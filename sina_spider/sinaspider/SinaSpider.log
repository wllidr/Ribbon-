2018-07-23 00:50:57 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 00:50:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 00:51:12 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 00:51:12 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 00:51:12 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 00:51:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 00:51:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-23 00:51:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-23 00:51:19 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-23 00:51:19 [twisted] CRITICAL: Unhandled error in Deferred:
2018-07-23 00:51:19 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 81, in crawl
    start_requests = iter(self.spider.start_requests())
TypeError: 'NoneType' object is not iterable
2018-07-23 08:53:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 08:53:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 08:53:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 08:53:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 08:53:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-23 08:53:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-23 08:53:08 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-23 08:53:08 [scrapy.core.engine] INFO: Spider opened
2018-07-23 08:53:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-23 08:53:08 [sina_spider] INFO: Spider opened: sina_spider
2018-07-23 08:53:08 [sina_spider] INFO: Spider opened: sina_spider
2018-07-23 08:54:39 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 08:54:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 08:54:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 08:54:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 08:54:45 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-23 08:54:45 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-23 08:54:45 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-23 08:54:45 [scrapy.core.engine] INFO: Spider opened
2018-07-23 08:54:45 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-23 08:54:45 [sina_spider] INFO: Spider opened: sina_spider
2018-07-23 08:54:45 [sina_spider] INFO: Spider opened: sina_spider
2018-07-23 08:54:45 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 33, in process_request
    cookies = self._get_request_cookies(jar, request)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in _get_request_cookies
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in <listcomp>
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 74, in _format_cookie
    cookie_str = '%s=%s' % (cookie['name'], cookie['value'])
KeyError: 'name'
2018-07-23 08:54:45 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/fans>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 33, in process_request
    cookies = self._get_request_cookies(jar, request)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in _get_request_cookies
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in <listcomp>
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 74, in _format_cookie
    cookie_str = '%s=%s' % (cookie['name'], cookie['value'])
KeyError: 'name'
2018-07-23 08:54:45 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/attgroup/opening?uid=5235640836>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 33, in process_request
    cookies = self._get_request_cookies(jar, request)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in _get_request_cookies
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in <listcomp>
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 74, in _format_cookie
    cookie_str = '%s=%s' % (cookie['name'], cookie['value'])
KeyError: 'name'
2018-07-23 08:54:45 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/profile?filter=1&page=1>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 33, in process_request
    cookies = self._get_request_cookies(jar, request)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in _get_request_cookies
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in <listcomp>
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 74, in _format_cookie
    cookie_str = '%s=%s' % (cookie['name'], cookie['value'])
KeyError: 'name'
2018-07-23 08:54:45 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-23 08:54:45 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 4,
 'downloader/exception_type_count/builtins.KeyError': 4,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 23, 0, 54, 45, 627224),
 'log_count/ERROR': 4,
 'log_count/INFO': 9,
 'scheduler/dequeued': 4,
 'scheduler/dequeued/memory': 4,
 'scheduler/enqueued': 4,
 'scheduler/enqueued/memory': 4,
 'start_time': datetime.datetime(2018, 7, 23, 0, 54, 45, 350208)}
2018-07-23 08:54:45 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-23 08:55:13 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 08:55:13 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 08:55:13 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 08:55:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 08:55:35 [twisted] CRITICAL: Unhandled error in Deferred:
2018-07-23 08:55:35 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connection.py", line 141, in _new_conn
    (self.host, self.port), self.timeout, **extra_kw)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\util\connection.py", line 83, in create_connection
    raise err
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
TimeoutError: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 601, in urlopen
    chunked=chunked)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 346, in _make_request
    self._validate_conn(conn)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 850, in _validate_conn
    conn.connect()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connection.py", line 284, in connect
    conn = self._new_conn()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connection.py", line 150, in _new_conn
    self, "Failed to establish a new connection: %s" % e)
urllib3.exceptions.NewConnectionError: <urllib3.connection.VerifiedHTTPSConnection object at 0x07C44A90>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='login.sina.com.cn', port=443): Max retries exceeded with url: /sso/login.php?client=ssologin.js(v1.4.19) (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x07C44A90>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 10, in <module>
    from sina.util.cookies import cookie
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 77, in <module>
    cookie = getCookies(accountPwdPool)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 57, in getCookies
    r = session.post(loginURL, data=postData)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 555, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\adapters.py", line 508, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='login.sina.com.cn', port=443): Max retries exceeded with url: /sso/login.php?client=ssologin.js(v1.4.19) (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x07C44A90>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',))
2018-07-23 08:56:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 08:56:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 08:56:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 08:56:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 08:56:51 [twisted] CRITICAL: Unhandled error in Deferred:
2018-07-23 08:56:51 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\contrib\pyopenssl.py", line 441, in wrap_socket
    cnx.do_handshake()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\OpenSSL\SSL.py", line 1806, in do_handshake
    self._raise_ssl_error(self._ssl, result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\OpenSSL\SSL.py", line 1546, in _raise_ssl_error
    _raise_current_error()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\OpenSSL\_util.py", line 54, in exception_from_error_queue
    raise exception_type(errors)
OpenSSL.SSL.Error: [('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 595, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 816, in _prepare_proxy
    conn.connect()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connection.py", line 326, in connect
    ssl_context=context)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\util\ssl_.py", line 329, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\contrib\pyopenssl.py", line 448, in wrap_socket
    raise ssl.SSLError('bad handshake: %r' % e)
ssl.SSLError: ("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='login.sina.com.cn', port=443): Max retries exceeded with url: /sso/login.php?client=ssologin.js(v1.4.19) (Caused by SSLError(SSLError("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 10, in <module>
    from sina.util.cookies import cookie
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 77, in <module>
    cookie = getCookies(accountPwdPool)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 57, in getCookies
    r = session.post(loginURL, data=postData)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 555, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\adapters.py", line 506, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='login.sina.com.cn', port=443): Max retries exceeded with url: /sso/login.php?client=ssologin.js(v1.4.19) (Caused by SSLError(SSLError("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",),))
2018-07-23 08:57:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 08:57:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 08:57:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 08:57:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 08:57:06 [twisted] CRITICAL: Unhandled error in Deferred:
2018-07-23 08:57:06 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\contrib\pyopenssl.py", line 441, in wrap_socket
    cnx.do_handshake()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\OpenSSL\SSL.py", line 1806, in do_handshake
    self._raise_ssl_error(self._ssl, result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\OpenSSL\SSL.py", line 1546, in _raise_ssl_error
    _raise_current_error()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\OpenSSL\_util.py", line 54, in exception_from_error_queue
    raise exception_type(errors)
OpenSSL.SSL.Error: [('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 595, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 816, in _prepare_proxy
    conn.connect()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connection.py", line 326, in connect
    ssl_context=context)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\util\ssl_.py", line 329, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\contrib\pyopenssl.py", line 448, in wrap_socket
    raise ssl.SSLError('bad handshake: %r' % e)
ssl.SSLError: ("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='login.sina.com.cn', port=443): Max retries exceeded with url: /sso/login.php?client=ssologin.js(v1.4.19) (Caused by SSLError(SSLError("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 10, in <module>
    from sina.util.cookies import cookie
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 77, in <module>
    cookie = getCookies(accountPwdPool)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 57, in getCookies
    r = session.post(loginURL, data=postData)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 555, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\adapters.py", line 506, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='login.sina.com.cn', port=443): Max retries exceeded with url: /sso/login.php?client=ssologin.js(v1.4.19) (Caused by SSLError(SSLError("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",),))
2018-07-23 08:57:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 08:57:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 08:57:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 08:57:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 08:57:26 [twisted] CRITICAL: Unhandled error in Deferred:
2018-07-23 08:57:26 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\contrib\pyopenssl.py", line 441, in wrap_socket
    cnx.do_handshake()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\OpenSSL\SSL.py", line 1806, in do_handshake
    self._raise_ssl_error(self._ssl, result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\OpenSSL\SSL.py", line 1546, in _raise_ssl_error
    _raise_current_error()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\OpenSSL\_util.py", line 54, in exception_from_error_queue
    raise exception_type(errors)
OpenSSL.SSL.Error: [('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 595, in urlopen
    self._prepare_proxy(conn)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 816, in _prepare_proxy
    conn.connect()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connection.py", line 326, in connect
    ssl_context=context)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\util\ssl_.py", line 329, in ssl_wrap_socket
    return context.wrap_socket(sock, server_hostname=server_hostname)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\contrib\pyopenssl.py", line 448, in wrap_socket
    raise ssl.SSLError('bad handshake: %r' % e)
ssl.SSLError: ("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\adapters.py", line 440, in send
    timeout=timeout
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py", line 639, in urlopen
    _stacktrace=sys.exc_info()[2])
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\util\retry.py", line 388, in increment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='login.sina.com.cn', port=443): Max retries exceeded with url: /sso/login.php?client=ssologin.js(v1.4.19) (Caused by SSLError(SSLError("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",),))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 10, in <module>
    from sina.util.cookies import cookie
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 77, in <module>
    cookie = getCookies(accountPwdPool)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 57, in getCookies
    r = session.post(loginURL, data=postData)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 555, in post
    return self.request('POST', url, data=data, json=json, **kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 508, in request
    resp = self.send(prep, **send_kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\sessions.py", line 618, in send
    r = adapter.send(request, **kwargs)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\requests\adapters.py", line 506, in send
    raise SSLError(e, request=request)
requests.exceptions.SSLError: HTTPSConnectionPool(host='login.sina.com.cn', port=443): Max retries exceeded with url: /sso/login.php?client=ssologin.js(v1.4.19) (Caused by SSLError(SSLError("bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)",),))
2018-07-23 08:57:47 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 08:57:47 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 08:57:47 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 08:57:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 08:57:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-23 08:57:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-23 08:57:48 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-23 08:57:48 [scrapy.core.engine] INFO: Spider opened
2018-07-23 08:57:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-23 08:58:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-23 08:59:28 [scrapy.core.scraper] ERROR: Error downloading <GET https://passport.weibo.cn/signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&filter=1&page=1&uid=5235640836&_T_WM=d285e214778c1935b8adafc2d1c60f3d>: Could not open CONNECT tunnel with proxy 127.0.0.1:8888 [{'status': 502, 'reason': b'Fiddler - DNS Lookup Failed'}]
2018-07-23 08:59:29 [scrapy.core.scraper] ERROR: Error downloading <GET https://passport.weibo.cn/signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&filter_by_author=&filter_by_type=&_T_WM=bc77964c33af2dbbabb1bcc14e21d20f>: Could not open CONNECT tunnel with proxy 127.0.0.1:8888 [{'status': 502, 'reason': b'Fiddler - DNS Lookup Failed'}]
2018-07-23 08:59:29 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-23 08:59:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 5,
 'downloader/exception_type_count/scrapy.core.downloader.handlers.http11.TunnelError': 5,
 'downloader/request_bytes': 6160,
 'downloader/request_count': 16,
 'downloader/request_method_count/GET': 16,
 'downloader/response_bytes': 18307,
 'downloader/response_count': 11,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 8,
 'downloader/response_status_count/502': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 23, 0, 59, 29, 779477),
 'item_scraped_count': 2,
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'response_received_count': 2,
 'retry/count': 4,
 'retry/max_reached': 2,
 'retry/reason_count/502 Bad Gateway': 1,
 'retry/reason_count/scrapy.core.downloader.handlers.http11.TunnelError': 3,
 'scheduler/dequeued': 16,
 'scheduler/dequeued/memory': 16,
 'scheduler/enqueued': 16,
 'scheduler/enqueued/memory': 16,
 'start_time': datetime.datetime(2018, 7, 23, 0, 57, 48, 403679)}
2018-07-23 08:59:29 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-23 09:03:39 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 09:03:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 09:03:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 09:03:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 09:03:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-23 09:03:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-23 09:03:40 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-23 09:03:40 [scrapy.core.engine] INFO: Spider opened
2018-07-23 09:03:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-23 09:04:19 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-23 09:04:19 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 2,
 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 2,
 'downloader/request_bytes': 5054,
 'downloader/request_count': 14,
 'downloader/request_method_count/GET': 14,
 'downloader/response_bytes': 13682,
 'downloader/response_count': 12,
 'downloader/response_status_count/200': 4,
 'downloader/response_status_count/302': 8,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 23, 1, 4, 19, 564052),
 'item_scraped_count': 4,
 'log_count/INFO': 7,
 'response_received_count': 4,
 'retry/count': 2,
 'retry/reason_count/twisted.internet.error.TCPTimedOutError': 2,
 'scheduler/dequeued': 14,
 'scheduler/dequeued/memory': 14,
 'scheduler/enqueued': 14,
 'scheduler/enqueued/memory': 14,
 'start_time': datetime.datetime(2018, 7, 23, 1, 3, 40, 617824)}
2018-07-23 09:04:19 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-23 13:01:18 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 13:01:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 13:01:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 13:01:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 13:01:19 [cookError] WARNING: HTTPSConnectionPool(host='login.sina.com.cn', port=443): Max retries exceeded with url: /sso/login.php?client=ssologin.js(v1.4.18) (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x07C47830>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))
2018-07-23 13:01:19 [twisted] CRITICAL: Unhandled error in Deferred:
2018-07-23 13:01:19 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 10, in <module>
    from sina.util.cookies import cookies
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 83, in <module>
    cookies = getCookies(accountPwdPool)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 64, in getCookies
    if r.status_code == 200:
UnboundLocalError: local variable 'r' referenced before assignment
2018-07-23 13:01:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 13:01:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 13:01:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 13:01:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 13:01:42 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-23 13:01:42 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-23 13:01:42 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-23 13:01:42 [scrapy.core.engine] INFO: Spider opened
2018-07-23 13:01:42 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-23 13:01:42 [sina_spider] INFO: Spider opened: sina_spider
2018-07-23 13:02:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://login.sina.com.cn/crossdomain2.php?action=logout&r=https%3A%2F%2Flogin.sina.com.cn> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 81, in parseFans
    nextpage = re.findall('<a href="([\s\S]*?)">下页</a>')
TypeError: findall() missing 1 required positional argument: 'string'
2018-07-23 13:03:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-23 13:03:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-23 13:03:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-23 13:03:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-23 13:03:19 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-23 13:03:19 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-23 13:03:19 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-23 13:03:19 [scrapy.core.engine] INFO: Spider opened
2018-07-23 13:03:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-23 13:03:19 [sina_spider] INFO: Spider opened: sina_spider
2018-07-23 13:04:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://login.sina.com.cn/crossdomain2.php?action=logout&r=http%3A%2F%2Fm.weibo.cn> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 59, in parseAttention
    nextpage = re.findall('<a href="([\s\S]*?)">下页</a>')
TypeError: findall() missing 1 required positional argument: 'string'
2018-07-23 13:04:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://login.sina.com.cn/crossdomain2.php?action=logout&r=https%3A%2F%2Flogin.sina.com.cn> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 82, in parseFans
    nextpage = re.findall('<a href="([\s\S]*?)">下页</a>')
TypeError: findall() missing 1 required positional argument: 'string'
2018-07-23 13:04:16 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-23 13:04:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 27942,
 'downloader/request_count': 24,
 'downloader/request_method_count/GET': 24,
 'downloader/response_bytes': 23567,
 'downloader/response_count': 24,
 'downloader/response_status_count/200': 4,
 'downloader/response_status_count/302': 20,
 'dupefilter/filtered': 2,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 23, 5, 4, 16, 125488),
 'log_count/ERROR': 2,
 'log_count/INFO': 8,
 'response_received_count': 2,
 'scheduler/dequeued': 24,
 'scheduler/dequeued/memory': 24,
 'scheduler/enqueued': 24,
 'scheduler/enqueued/memory': 24,
 'spider_exceptions/TypeError': 2,
 'start_time': datetime.datetime(2018, 7, 23, 5, 3, 19, 843269)}
2018-07-23 13:04:16 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:30:49 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:30:49 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:30:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 09:30:49 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:31:09 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:31:10 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:31:10 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:31:11 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:31:12 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:31:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:31:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:31:13 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:31:13 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:31:13 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:31:13 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 66, in process_request
    cookie = random.choice(cookies)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\random.py", line 258, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
2018-07-24 09:31:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:31:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.IndexError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 31, 14, 60805),
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 5,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 31, 13, 731786)}
2018-07-24 09:31:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:36:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:36:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:36:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:36:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:36:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:36:06 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /sso/prelogin.php?entry=weibo&callback=sinaSSOController.preloginCallBack&su=MTMxMTMxMjEyMDI=&rsakt=mod&checkpin=1&client=ssologin.js(v1.4.18)&_=1532396166815 HTTP/1.1" 200 None
2018-07-24 09:36:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:36:07 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /cgi/pin.php?r=49879419&s=0&p=gz-9e433076e7b677b53b5925438605d4f6e309 HTTP/1.1" 200 None
2018-07-24 09:36:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:07 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 21
2018-07-24 09:36:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:07 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 37
2018-07-24 09:36:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:08 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 36
2018-07-24 09:36:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:08 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:36:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:09 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:36:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:10 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:36:11 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:12 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:36:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:13 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:36:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:14 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:36:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:36:16 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 41
2018-07-24 09:36:16 [urllib3.connectionpool] DEBUG: Resetting dropped connection: login.sina.com.cn
2018-07-24 09:36:17 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:36:17 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.com
2018-07-24 09:36:17 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:36:18 [urllib3.connectionpool] DEBUG: https://passport.weibo.com:443 "GET /wbsso/login?ssosavestate=1563932176&url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.feedBackUrlCallBack&display=0&ticket=ST-NjYwNzU4MzM4NQ==-1532396176-gz-2F83A15C842A8AC7771BBE0C7D35DC22-1&retcode=0 HTTP/1.1" 302 None
2018-07-24 09:36:18 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): weibo.com
2018-07-24 09:36:18 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 301 276
2018-07-24 09:36:18 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.com
2018-07-24 09:36:18 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:36:19 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 200 None
2018-07-24 09:36:19 [urllib3.connectionpool] DEBUG: Resetting dropped connection: weibo.com
2018-07-24 09:36:19 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 301 276
2018-07-24 09:36:19 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:36:19 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 200 None
2018-07-24 09:36:19 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.cn
2018-07-24 09:36:20 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:36:20 [urllib3.connectionpool] DEBUG: https://weibo.cn:443 "GET /5235640836/follow HTTP/1.1" 302 20
2018-07-24 09:36:20 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.cn
2018-07-24 09:36:20 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:36:20 [urllib3.connectionpool] DEBUG: https://passport.weibo.cn:443 "GET /signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=b6991bf6730cf9caad6b16715a834250 HTTP/1.1" 200 None
2018-07-24 09:36:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:36:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:36:21 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:36:21 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:36:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:36:21 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:36:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 66, in process_request
    cookie = random.choice(cookies)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\random.py", line 258, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
2018-07-24 09:36:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:36:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.IndexError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 36, 21, 320379),
 'log_count/DEBUG': 40,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 5,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 36, 21, 100366)}
2018-07-24 09:36:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:37:02 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:37:02 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:37:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:37:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:37:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:37:03 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /sso/prelogin.php?entry=weibo&callback=sinaSSOController.preloginCallBack&su=MTMxMTMxMjEyMDI=&rsakt=mod&checkpin=1&client=ssologin.js(v1.4.18)&_=1532396223269 HTTP/1.1" 200 None
2018-07-24 09:37:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:37:03 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /cgi/pin.php?r=12486408&s=0&p=gz-c3fb821ba06f883be227259d3532d730628e HTTP/1.1" 200 None
2018-07-24 09:37:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:37:03 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 21
2018-07-24 09:37:03 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:37:04 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 37
2018-07-24 09:37:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:37:04 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 36
2018-07-24 09:37:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:37:05 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:37:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:37:06 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:37:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:37:07 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:37:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:37:08 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:37:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:37:10 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 41
2018-07-24 09:37:10 [urllib3.connectionpool] DEBUG: Resetting dropped connection: login.sina.com.cn
2018-07-24 09:37:11 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:37:11 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.com
2018-07-24 09:37:11 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:37:12 [urllib3.connectionpool] DEBUG: https://passport.weibo.com:443 "GET /wbsso/login?ssosavestate=1563932230&url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.feedBackUrlCallBack&display=0&ticket=ST-NjYwNzU4MzM4NQ==-1532396230-gz-309FC1EE31FF103E3CAA2AB16114CB95-1&retcode=0 HTTP/1.1" 302 None
2018-07-24 09:37:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): weibo.com
2018-07-24 09:37:12 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 301 276
2018-07-24 09:37:12 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.com
2018-07-24 09:37:12 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:37:12 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 200 None
2018-07-24 09:37:12 [urllib3.connectionpool] DEBUG: Resetting dropped connection: weibo.com
2018-07-24 09:37:12 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 301 276
2018-07-24 09:37:12 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:37:13 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 200 None
2018-07-24 09:37:13 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.cn
2018-07-24 09:37:13 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:37:13 [urllib3.connectionpool] DEBUG: https://weibo.cn:443 "GET /5235640836/follow HTTP/1.1" 302 20
2018-07-24 09:37:13 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.cn
2018-07-24 09:37:14 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:37:14 [urllib3.connectionpool] DEBUG: https://passport.weibo.cn:443 "GET /signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=889666cde90f634b24a8b0ea23528fbb HTTP/1.1" 200 None
2018-07-24 09:37:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:37:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:37:14 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:37:14 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:37:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:37:14 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:37:14 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 68, in process_request
    cookie = random.choice(cookies)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\random.py", line 258, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
2018-07-24 09:37:14 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:37:14 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.IndexError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 37, 14, 962447),
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 5,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 37, 14, 741434)}
2018-07-24 09:37:14 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:38:43 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:38:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:38:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:38:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:38:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:38:43 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /sso/prelogin.php?entry=weibo&callback=sinaSSOController.preloginCallBack&su=MTMxMTMxMjEyMDI=&rsakt=mod&checkpin=1&client=ssologin.js(v1.4.18)&_=1532396323400 HTTP/1.1" 200 None
2018-07-24 09:38:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:38:43 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /cgi/pin.php?r=17437698&s=0&p=gz-e27f20009893a6a1b7f61885f57e2f29b37b HTTP/1.1" 200 None
2018-07-24 09:38:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:38:43 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 21
2018-07-24 09:38:43 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:38:44 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 37
2018-07-24 09:38:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:38:44 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 36
2018-07-24 09:38:44 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:38:45 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:38:46 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:38:46 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:38:47 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:38:47 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:38:48 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:38:49 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:38:50 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:38:50 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 41
2018-07-24 09:38:50 [urllib3.connectionpool] DEBUG: Resetting dropped connection: login.sina.com.cn
2018-07-24 09:38:51 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:38:51 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.com
2018-07-24 09:38:52 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:38:52 [urllib3.connectionpool] DEBUG: https://passport.weibo.com:443 "GET /wbsso/login?ssosavestate=1563932330&url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.feedBackUrlCallBack&display=0&ticket=ST-NjYwNzU4MzM4NQ==-1532396330-gz-8FE61B7F32F872D7D8BD2996B0658D5E-1&retcode=0 HTTP/1.1" 302 None
2018-07-24 09:38:52 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): weibo.com
2018-07-24 09:38:52 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 301 276
2018-07-24 09:38:53 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.com
2018-07-24 09:38:53 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:38:53 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 200 None
2018-07-24 09:38:53 [urllib3.connectionpool] DEBUG: Resetting dropped connection: weibo.com
2018-07-24 09:38:53 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 301 276
2018-07-24 09:38:53 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:38:54 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 200 None
2018-07-24 09:38:54 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.cn
2018-07-24 09:38:54 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:38:54 [urllib3.connectionpool] DEBUG: https://weibo.cn:443 "GET /5235640836/follow HTTP/1.1" 302 20
2018-07-24 09:38:54 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.cn
2018-07-24 09:38:54 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:38:54 [urllib3.connectionpool] DEBUG: https://passport.weibo.cn:443 "GET /signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=333d26e987f59e4d08a8aba74b1bb93b HTTP/1.1" 200 None
2018-07-24 09:38:55 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:38:55 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:38:55 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:38:55 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:38:55 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:38:55 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:38:55 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 68, in process_request
    cookie = random.choice(cookies)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\random.py", line 258, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
2018-07-24 09:38:55 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:38:55 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.IndexError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 38, 55, 378191),
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 5,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 38, 55, 154178)}
2018-07-24 09:38:55 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:39:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:39:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:39:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:39:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:39:56 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:39:57 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /sso/prelogin.php?entry=weibo&callback=sinaSSOController.preloginCallBack&su=MTMxMTMxMjEyMDI=&rsakt=mod&checkpin=1&client=ssologin.js(v1.4.18)&_=1532396396958 HTTP/1.1" 200 None
2018-07-24 09:39:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:39:57 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /cgi/pin.php?r=1622262&s=0&p=gz-c8977fbcb5572682ad2572fca9b169267d87 HTTP/1.1" 200 None
2018-07-24 09:39:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:39:57 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 21
2018-07-24 09:39:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:39:57 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 37
2018-07-24 09:39:57 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:39:58 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 36
2018-07-24 09:39:58 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:39:59 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:40:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:40:00 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:40:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:40:01 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:40:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:40:03 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:40:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:40:04 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:40:05 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:40:05 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:40:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:40:07 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 41
2018-07-24 09:40:07 [urllib3.connectionpool] DEBUG: Resetting dropped connection: login.sina.com.cn
2018-07-24 09:40:08 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:40:08 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.com
2018-07-24 09:40:09 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:40:09 [urllib3.connectionpool] DEBUG: https://passport.weibo.com:443 "GET /wbsso/login?ssosavestate=1563932407&url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.feedBackUrlCallBack&display=0&ticket=ST-NjYwNzU4MzM4NQ==-1532396407-gz-293915FA63A1012F7FEAE6600434CC03-1&retcode=0 HTTP/1.1" 302 None
2018-07-24 09:40:09 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): weibo.com
2018-07-24 09:40:09 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 301 276
2018-07-24 09:40:10 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.com
2018-07-24 09:40:10 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:40:10 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 200 None
2018-07-24 09:40:10 [urllib3.connectionpool] DEBUG: Resetting dropped connection: weibo.com
2018-07-24 09:40:10 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 301 276
2018-07-24 09:40:10 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:40:11 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 200 None
2018-07-24 09:40:11 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.cn
2018-07-24 09:40:11 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:40:11 [urllib3.connectionpool] DEBUG: https://weibo.cn:443 "GET /5235640836/follow HTTP/1.1" 302 20
2018-07-24 09:40:11 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.cn
2018-07-24 09:40:11 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:40:11 [urllib3.connectionpool] DEBUG: https://passport.weibo.cn:443 "GET /signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=a8044714266488a0ae3632af826e0abc HTTP/1.1" 200 None
2018-07-24 09:40:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:40:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:40:12 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:40:12 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:40:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:40:12 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:40:12 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 62, in process_request
    cookie = random.choice(cookies)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\random.py", line 258, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
2018-07-24 09:40:12 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:40:12 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.IndexError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 40, 12, 517603),
 'log_count/DEBUG': 40,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 5,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 40, 12, 297590)}
2018-07-24 09:40:12 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:41:16 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:41:16 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:41:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:41:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:41:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:41:17 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /sso/prelogin.php?entry=weibo&callback=sinaSSOController.preloginCallBack&su=MTMxMTMxMjEyMDI=&rsakt=mod&checkpin=1&client=ssologin.js(v1.4.18)&_=1532396477269 HTTP/1.1" 200 None
2018-07-24 09:41:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:41:17 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /cgi/pin.php?r=28877590&s=0&p=gz-2ea01e9101f3ea9fc346e61ab8fbc90f9e85 HTTP/1.1" 200 None
2018-07-24 09:41:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:19 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 21
2018-07-24 09:41:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:19 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 37
2018-07-24 09:41:19 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:20 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 36
2018-07-24 09:41:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:20 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:41:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:22 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:41:23 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:23 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:41:24 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:25 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:41:26 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:26 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:41:27 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:28 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:41:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:29 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:41:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:41:31 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 41
2018-07-24 09:41:31 [urllib3.connectionpool] DEBUG: Resetting dropped connection: login.sina.com.cn
2018-07-24 09:41:32 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:41:32 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.com
2018-07-24 09:41:32 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:41:32 [urllib3.connectionpool] DEBUG: https://passport.weibo.com:443 "GET /wbsso/login?ssosavestate=1563932490&url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.feedBackUrlCallBack&display=0&ticket=ST-NjYwNzU4MzM4NQ==-1532396490-gz-EFC7BAE24C26C46F1EEFD036C122A969-1&retcode=0 HTTP/1.1" 302 None
2018-07-24 09:41:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): weibo.com
2018-07-24 09:41:33 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 301 276
2018-07-24 09:41:33 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.com
2018-07-24 09:41:33 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:41:33 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 200 None
2018-07-24 09:41:33 [urllib3.connectionpool] DEBUG: Resetting dropped connection: weibo.com
2018-07-24 09:41:33 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 301 276
2018-07-24 09:41:33 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:41:34 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 200 None
2018-07-24 09:41:34 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.cn
2018-07-24 09:41:34 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:41:34 [urllib3.connectionpool] DEBUG: https://weibo.cn:443 "GET /5235640836/follow HTTP/1.1" 302 20
2018-07-24 09:41:34 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.cn
2018-07-24 09:41:34 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:41:34 [urllib3.connectionpool] DEBUG: https://passport.weibo.cn:443 "GET /signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=75cfbdc29ef64afd3d1f2ba607a552a7 HTTP/1.1" 200 None
2018-07-24 09:41:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:41:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:41:35 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:41:35 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:41:35 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:41:35 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 09:41:35 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:41:35 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 62, in process_request
    cookie = random.choice(cookies)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\random.py", line 258, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
2018-07-24 09:41:35 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:41:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.IndexError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 41, 35, 610355),
 'log_count/DEBUG': 42,
 'log_count/ERROR': 1,
 'log_count/INFO': 8,
 'log_count/WARNING': 5,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 41, 35, 395343)}
2018-07-24 09:41:35 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:42:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:42:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:42:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:42:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:42:28 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:42:29 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /sso/prelogin.php?entry=weibo&callback=sinaSSOController.preloginCallBack&su=MTMxMTMxMjEyMDI=&rsakt=mod&checkpin=1&client=ssologin.js(v1.4.18)&_=1532396548987 HTTP/1.1" 200 None
2018-07-24 09:42:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:42:29 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /cgi/pin.php?r=52774218&s=0&p=gz-3fb6ff17236201822ddd683d0e7fd2d94ce6 HTTP/1.1" 200 None
2018-07-24 09:42:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:42:29 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 21
2018-07-24 09:42:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:42:29 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 37
2018-07-24 09:42:29 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:42:30 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 36
2018-07-24 09:42:30 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:42:31 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:42:32 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:42:32 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:42:33 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:42:34 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:42:35 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:42:36 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:42:37 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:42:38 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 41
2018-07-24 09:42:38 [urllib3.connectionpool] DEBUG: Resetting dropped connection: login.sina.com.cn
2018-07-24 09:42:39 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:42:39 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.com
2018-07-24 09:42:40 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:42:40 [urllib3.connectionpool] DEBUG: https://passport.weibo.com:443 "GET /wbsso/login?ssosavestate=1563932558&url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.feedBackUrlCallBack&display=0&ticket=ST-NjYwNzU4MzM4NQ==-1532396558-gz-1209CFC0CDF2DAFB7D8A29010D2AD010-1&retcode=0 HTTP/1.1" 302 None
2018-07-24 09:42:40 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): weibo.com
2018-07-24 09:42:40 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 301 276
2018-07-24 09:42:40 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.com
2018-07-24 09:42:41 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:42:41 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 200 None
2018-07-24 09:42:41 [urllib3.connectionpool] DEBUG: Resetting dropped connection: weibo.com
2018-07-24 09:42:41 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 301 276
2018-07-24 09:42:41 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:42:41 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 200 None
2018-07-24 09:42:41 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.cn
2018-07-24 09:42:42 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:42:42 [urllib3.connectionpool] DEBUG: https://weibo.cn:443 "GET /5235640836/follow HTTP/1.1" 302 20
2018-07-24 09:42:42 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.cn
2018-07-24 09:42:42 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:42:42 [urllib3.connectionpool] DEBUG: https://passport.weibo.cn:443 "GET /signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=c4210ed2c67d6115988b4400418b2298 HTTP/1.1" 200 None
2018-07-24 09:42:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:42:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:42:43 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:42:43 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:42:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:42:43 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:42:43 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 62, in process_request
    cookie = random.choice(cookies)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\random.py", line 258, in choice
    raise IndexError('Cannot choose from an empty sequence') from None
IndexError: Cannot choose from an empty sequence
2018-07-24 09:42:43 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:42:43 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.IndexError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 42, 43, 334229),
 'log_count/DEBUG': 36,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 5,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 42, 43, 116216)}
2018-07-24 09:42:43 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:43:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:43:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:43:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:43:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:43:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:43:14 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /sso/prelogin.php?entry=weibo&callback=sinaSSOController.preloginCallBack&su=MTMxMTMxMjEyMDI=&rsakt=mod&checkpin=1&client=ssologin.js(v1.4.18)&_=1532396594742 HTTP/1.1" 200 None
2018-07-24 09:43:14 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:43:15 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /cgi/pin.php?r=97429341&s=0&p=gz-907e212ebbd4a18faf16850cbee84c12af4e HTTP/1.1" 200 None
2018-07-24 09:43:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:43:15 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 21
2018-07-24 09:43:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:43:16 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 37
2018-07-24 09:43:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:43:16 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 36
2018-07-24 09:43:16 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:43:16 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:43:17 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:43:19 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:43:20 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:43:20 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:43:21 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:43:22 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 41
2018-07-24 09:43:22 [urllib3.connectionpool] DEBUG: Resetting dropped connection: login.sina.com.cn
2018-07-24 09:43:24 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:43:24 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.com
2018-07-24 09:43:24 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:43:25 [urllib3.connectionpool] DEBUG: https://passport.weibo.com:443 "GET /wbsso/login?ssosavestate=1563932602&url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.feedBackUrlCallBack&display=0&ticket=ST-NjYwNzU4MzM4NQ==-1532396602-gz-192F8ED227DC2843917261E2D299B2F1-1&retcode=0 HTTP/1.1" 302 None
2018-07-24 09:43:25 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): weibo.com
2018-07-24 09:43:25 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 301 276
2018-07-24 09:43:25 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.com
2018-07-24 09:43:25 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:43:25 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 200 None
2018-07-24 09:43:25 [urllib3.connectionpool] DEBUG: Resetting dropped connection: weibo.com
2018-07-24 09:43:26 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 301 276
2018-07-24 09:43:26 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:43:27 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 200 None
2018-07-24 09:43:27 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.cn
2018-07-24 09:43:27 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:43:27 [urllib3.connectionpool] DEBUG: https://weibo.cn:443 "GET /5235640836/follow HTTP/1.1" 302 20
2018-07-24 09:43:27 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.cn
2018-07-24 09:43:27 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:43:27 [urllib3.connectionpool] DEBUG: https://passport.weibo.cn:443 "GET /signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=3864cb9f32a51021e8fe31aa1ae86eb0 HTTP/1.1" 200 None
2018-07-24 09:43:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:43:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:43:28 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:43:28 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:43:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:43:28 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:43:28 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 74, in process_request
    print(cookie)
NameError: name 'cookie' is not defined
2018-07-24 09:43:28 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:43:28 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.NameError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 43, 28, 561816),
 'log_count/DEBUG': 34,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 5,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 43, 28, 331803)}
2018-07-24 09:43:28 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:50:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:50:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:50:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:50:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:50:00 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:50:01 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /sso/prelogin.php?entry=weibo&callback=sinaSSOController.preloginCallBack&su=MTMxMTMxMjEyMDI=&rsakt=mod&checkpin=1&client=ssologin.js(v1.4.18)&_=1532397000797 HTTP/1.1" 200 None
2018-07-24 09:50:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): login.sina.com.cn
2018-07-24 09:50:01 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "GET /cgi/pin.php?r=28789523&s=0&p=gz-b72c802eaab29716f832acef13873af2c946 HTTP/1.1" 200 None
2018-07-24 09:50:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:01 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 21
2018-07-24 09:50:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:01 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 37
2018-07-24 09:50:01 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:02 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 36
2018-07-24 09:50:02 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:03 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:50:04 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:05 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:50:06 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:06 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:50:07 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:07 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:50:08 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:09 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:50:10 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:11 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:50:12 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:12 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 40
2018-07-24 09:50:13 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): api.yundama.com
2018-07-24 09:50:14 [urllib3.connectionpool] DEBUG: http://api.yundama.com:80 "POST /api.php HTTP/1.1" 200 41
2018-07-24 09:50:14 [urllib3.connectionpool] DEBUG: Resetting dropped connection: login.sina.com.cn
2018-07-24 09:50:15 [urllib3.connectionpool] DEBUG: http://login.sina.com.cn:80 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:50:15 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.com
2018-07-24 09:50:15 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:50:15 [urllib3.connectionpool] DEBUG: https://passport.weibo.com:443 "GET /wbsso/login?ssosavestate=1563933013&url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.feedBackUrlCallBack&display=0&ticket=ST-NjYwNzU4MzM4NQ==-1532397013-gz-9F77C092D902FF37222129FEDEBAB3E6-1&retcode=0 HTTP/1.1" 302 None
2018-07-24 09:50:15 [urllib3.connectionpool] DEBUG: Starting new HTTP connection (1): weibo.com
2018-07-24 09:50:16 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 301 276
2018-07-24 09:50:16 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.com
2018-07-24 09:50:16 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:50:16 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /ajaxlogin.php?framelogin=1&callback=parent.sinaSSOController.feedBackUrlCallBack HTTP/1.1" 200 None
2018-07-24 09:50:16 [urllib3.connectionpool] DEBUG: Resetting dropped connection: weibo.com
2018-07-24 09:50:16 [urllib3.connectionpool] DEBUG: http://weibo.com:80 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 301 276
2018-07-24 09:50:16 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:50:17 [urllib3.connectionpool] DEBUG: https://weibo.com:443 "GET /6607583385/profile?topnav=1&wvr=6&is_all=1 HTTP/1.1" 200 None
2018-07-24 09:50:17 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): weibo.cn
2018-07-24 09:50:17 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:50:17 [urllib3.connectionpool] DEBUG: https://weibo.cn:443 "GET /5235640836/follow HTTP/1.1" 302 20
2018-07-24 09:50:17 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): passport.weibo.cn
2018-07-24 09:50:18 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:50:18 [urllib3.connectionpool] DEBUG: https://passport.weibo.cn:443 "GET /signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=ba40cdc98d82b29c7e7973e338622e3b HTTP/1.1" 200 None
2018-07-24 09:50:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:50:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:50:18 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:50:18 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:50:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:50:18 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:50:18 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 33, in process_request
    cookies = self._get_request_cookies(jar, request)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in _get_request_cookies
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in <listcomp>
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 74, in _format_cookie
    cookie_str = '%s=%s' % (cookie['name'], cookie['value'])
TypeError: string indices must be integers
2018-07-24 09:50:18 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:50:18 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.TypeError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 50, 18, 965282),
 'log_count/DEBUG': 42,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 5,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 50, 18, 703267)}
2018-07-24 09:50:18 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:51:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:51:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:51:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:51:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:51:27 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): login.sina.com.cn
2018-07-24 09:51:28 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:51:29 [urllib3.connectionpool] DEBUG: https://login.sina.com.cn:443 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:51:29 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): login.sina.com.cn
2018-07-24 09:51:29 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:51:30 [urllib3.connectionpool] DEBUG: https://login.sina.com.cn:443 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:51:31 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:51:31 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:51:31 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:51:31 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:51:31 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:51:31 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:51:31 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://weibo.cn/5235640836/follow> from <GET http://weibo.cn/5235640836/follow>
2018-07-24 09:51:34 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://passport.weibo.cn/signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=7255aa0bc33110566d8d35a5724b5ce7> from <GET https://weibo.cn/5235640836/follow>
2018-07-24 09:51:37 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://login.sina.com.cn/sguide/sguide.php?entry=wapsso&r=https%3A%2F%2Fpassport.weibo.cn%2Fsignin%2Flogin%3Fentry%3Dmweibo%26r%3Dhttp%253A%252F%252Fweibo.cn%26uid%3D5235640836%26_T_WM%3D7255aa0bc33110566d8d35a5724b5ce7&sudaref=> from <GET https://passport.weibo.cn/signin/login?entry=mweibo&r=http%3A%2F%2Fweibo.cn&uid=5235640836&_T_WM=7255aa0bc33110566d8d35a5724b5ce7>
2018-07-24 09:51:39 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://security.weibo.com/rmabnormal/index?entry=wapsso&r=https%3A%2F%2Fpassport.weibo.cn%2Fsignin%2Flogin%3Fentry%3Dmweibo%26r%3Dhttp%253A%252F%252Fweibo.cn%26uid%3D5235640836%26_T_WM%3D7255aa0bc33110566d8d35a5724b5ce7> from <GET https://login.sina.com.cn/sguide/sguide.php?entry=wapsso&r=https%3A%2F%2Fpassport.weibo.cn%2Fsignin%2Flogin%3Fentry%3Dmweibo%26r%3Dhttp%253A%252F%252Fweibo.cn%26uid%3D5235640836%26_T_WM%3D7255aa0bc33110566d8d35a5724b5ce7&sudaref=>
2018-07-24 09:51:40 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET https://login.sina.com.cn/sso/logout.php?r=http%3A%2F%2Fm.weibo.cn> from <GET https://security.weibo.com/rmabnormal/index?entry=wapsso&r=https%3A%2F%2Fpassport.weibo.cn%2Fsignin%2Flogin%3Fentry%3Dmweibo%26r%3Dhttp%253A%252F%252Fweibo.cn%26uid%3D5235640836%26_T_WM%3D7255aa0bc33110566d8d35a5724b5ce7>
2018-07-24 09:51:42 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (meta refresh) to <GET https://login.sina.com.cn/crossdomain2.php?action=logout&r=http%3A%2F%2Fm.weibo.cn> from <GET https://login.sina.com.cn/sso/logout.php?r=http%3A%2F%2Fm.weibo.cn>
2018-07-24 09:51:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://login.sina.com.cn/crossdomain2.php?action=logout&r=http%3A%2F%2Fm.weibo.cn> (referer: None)
2018-07-24 09:51:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://login.sina.com.cn/crossdomain2.php?action=logout&r=http%3A%2F%2Fm.weibo.cn> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 62, in parseAttention
    nextpage = re.findall('<a href="([\s\S]*?)">下页</a>')
TypeError: findall() missing 1 required positional argument: 'string'
2018-07-24 09:51:46 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:51:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 7961,
 'downloader/request_count': 7,
 'downloader/request_method_count/GET': 7,
 'downloader/response_bytes': 7612,
 'downloader/response_count': 7,
 'downloader/response_status_count/200': 2,
 'downloader/response_status_count/302': 5,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 51, 46, 119267),
 'log_count/DEBUG': 12,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 2,
 'response_received_count': 1,
 'scheduler/dequeued': 7,
 'scheduler/dequeued/memory': 7,
 'scheduler/enqueued': 7,
 'scheduler/enqueued/memory': 7,
 'spider_exceptions/TypeError': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 51, 31, 244416)}
2018-07-24 09:51:46 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 09:53:18 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 09:53:18 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 09:53:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders'], 'USER_AGENT': ['Mozilla/5.0 (Linux; U; Android 2.3.6; en-us; Nexus S Build/GRK39F) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Avant Browser/1.2.789rel1 (http://www.avantbrowser.com)', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/532.5 (KHTML, like Gecko) Chrome/4.0.249.0 Safari/532.5', 'Mozilla/5.0 (Windows; U; Windows NT 5.2; en-US) AppleWebKit/532.9 (KHTML, like Gecko) Chrome/5.0.310.0 Safari/532.9', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US) AppleWebKit/534.7 (KHTML, like Gecko) Chrome/7.0.514.0 Safari/534.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/9.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.14 (KHTML, like Gecko) Chrome/10.0.601.0 Safari/534.14', 'Mozilla/5.0 (Windows; U; Windows NT 6.1; en-US) AppleWebKit/534.20 (KHTML, like Gecko) Chrome/11.0.672.2 Safari/534.20', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/534.27 (KHTML, like Gecko) Chrome/12.0.712.0 Safari/534.27', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.1 (KHTML, like Gecko) Chrome/13.0.782.24 Safari/535.1', 'Mozilla/5.0 (Windows NT 6.0) AppleWebKit/535.2 (KHTML, like Gecko) Chrome/15.0.874.120 Safari/535.2', 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/535.7 (KHTML, like Gecko) Chrome/16.0.912.36 Safari/535.7', 'Mozilla/5.0 (Windows; U; Windows NT 6.0 x64; en-US; rv:1.9pre) Gecko/2008072421 Minefield/3.0.2pre', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.10) Gecko/2009042316 Firefox/3.0.10', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-GB; rv:1.9.0.11) Gecko/2009060215 Firefox/3.0.11 (.NET CLR 3.5.30729)', 'Mozilla/5.0 (Windows; U; Windows NT 6.0; en-US; rv:1.9.1.6) Gecko/20091201 Firefox/3.5.6 GTB5', 'Mozilla/5.0 (Windows; U; Windows NT 5.1; tr; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 ( .NET CLR 3.5.30729; .NET4.0E)', 'Mozilla/5.0 (Windows NT 6.1; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:2.0.1) Gecko/20100101 Firefox/4.0.1', 'Mozilla/5.0 (Windows NT 5.1; rv:5.0) Gecko/20100101 Firefox/5.0', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:6.0a2) Gecko/20110622 Firefox/6.0a2', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:7.0.1) Gecko/20100101 Firefox/7.0.1', 'Mozilla/5.0 (Windows NT 6.1; WOW64; rv:2.0b4pre) Gecko/20100815 Minefield/4.0b4pre', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT 5.0 )', 'Mozilla/4.0 (compatible; MSIE 5.5; Windows 98; Win 9x 4.90)', 'Mozilla/5.0 (Windows; U; Windows XP) Gecko MultiZilla/1.6.1.0a', 'Mozilla/2.02E (Win95; U)', 'Mozilla/3.01Gold (Win95; I)', 'Mozilla/4.8 [en] (Windows NT 5.1; U)', 'Mozilla/5.0 (Windows; U; Win98; en-US; rv:1.4) Gecko Netscape/7.1 (ax)', 'HTC_Dream Mozilla/5.0 (Linux; U; Android 1.5; en-ca; Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (hp-tablet; Linux; hpwOS/3.0.2; U; de-DE) AppleWebKit/534.6 (KHTML, like Gecko) wOSBrowser/234.40.1 Safari/534.6 TouchPad/1.0', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; sdk Build/CUPCAKE) AppleWebkit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Nexus One Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; htc_bahamas Build/CRB17) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.1-update1; de-de; HTC Desire 1.19.161.5 Build/ERE27) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 1.5; de-ch; HTC Hero Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; HTC Legend Build/cupcake) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 1.5; de-de; HTC Magic Build/PLAT-RC33) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1 FirePHP/0.3', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; HTC_TATTOO_A3288 Build/DRC79) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.0; en-us; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.5; en-us; T-Mobile G1 Build/CRB43) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari 525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.5; en-gb; T-Mobile_G2_Touch Build/CUPCAKE) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Droid Build/FRG22D) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Milestone Build/ SHOLS_U2_01.03.1) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.0.1; de-de; Milestone Build/SHOLS_U2_01.14.0) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 0.5; en-us) AppleWebKit/522  (KHTML, like Gecko) Safari/419.3', 'Mozilla/5.0 (Linux; U; Android 1.1; en-gb; dream) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 2.0; en-us; Droid Build/ESD20) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.1; en-us; Nexus One Build/ERD62) AppleWebKit/530.17 (KHTML, like Gecko) Version/4.0 Mobile Safari/530.17', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; Sprint APA9292KT Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-us; ADR6300 Build/FRF91) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 2.2; en-ca; GT-P1000M Build/FROYO) AppleWebKit/533.1 (KHTML, like Gecko) Version/4.0 Mobile Safari/533.1', 'Mozilla/5.0 (Linux; U; Android 3.0.1; fr-fr; A500 Build/HRI66) AppleWebKit/534.13 (KHTML, like Gecko) Version/4.0 Safari/534.13', 'Mozilla/5.0 (Linux; U; Android 3.0; en-us; Xoom Build/HRI39) AppleWebKit/525.10  (KHTML, like Gecko) Version/3.0.4 Mobile Safari/523.12.2', 'Mozilla/5.0 (Linux; U; Android 1.6; es-es; SonyEricssonX10i Build/R1FA016) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1', 'Mozilla/5.0 (Linux; U; Android 1.6; en-us; SonyEricssonX10i Build/R1AA056) AppleWebKit/528.5  (KHTML, like Gecko) Version/3.1.2 Mobile Safari/525.20.1']}
2018-07-24 09:53:18 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 09:53:18 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): login.sina.com.cn
2018-07-24 09:53:19 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:53:19 [urllib3.connectionpool] DEBUG: https://login.sina.com.cn:443 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:53:19 [urllib3.connectionpool] DEBUG: Starting new HTTPS connection (1): login.sina.com.cn
2018-07-24 09:53:20 [py.warnings] WARNING: C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\urllib3\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings
  InsecureRequestWarning)

2018-07-24 09:53:21 [urllib3.connectionpool] DEBUG: https://login.sina.com.cn:443 "POST /sso/login.php?client=ssologin.js(v1.4.18) HTTP/1.1" 200 None
2018-07-24 09:53:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 09:53:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 09:53:21 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 09:53:21 [scrapy.core.engine] INFO: Spider opened
2018-07-24 09:53:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 09:53:21 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-07-24 09:53:21 [scrapy.core.scraper] ERROR: Error downloading <GET http://weibo.cn/5235640836/follow>
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\middleware.py", line 37, in process_request
    response = yield method(request=request, spider=spider)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 33, in process_request
    cookies = self._get_request_cookies(jar, request)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in _get_request_cookies
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 90, in <listcomp>
    cookies = [self._format_cookie(x) for x in cookie_list]
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\downloadermiddlewares\cookies.py", line 74, in _format_cookie
    cookie_str = '%s=%s' % (cookie['name'], cookie['value'])
TypeError: string indices must be integers
2018-07-24 09:53:21 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 09:53:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/exception_count': 1,
 'downloader/exception_type_count/builtins.TypeError': 1,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 1, 53, 21, 796740),
 'log_count/DEBUG': 5,
 'log_count/ERROR': 1,
 'log_count/INFO': 7,
 'log_count/WARNING': 2,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2018, 7, 24, 1, 53, 21, 573727)}
2018-07-24 09:53:21 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 13:24:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 13:24:28 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 13:24:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 13:24:28 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 13:24:59 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 13:24:59 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 13:24:59 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 13:24:59 [scrapy.core.engine] INFO: Spider opened
2018-07-24 13:24:59 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 13:24:59 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:33:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:33:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:33:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:33:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:33:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:33:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:33:28 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:33:28 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:33:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:33:28 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:33:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:33:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:33:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:33:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:33:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:33:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:33:54 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:33:54 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:33:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:33:54 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:34:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:34:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:34:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:34:32 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:34:32 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:34:32 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:34:33 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:34:33 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:34:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:34:33 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:36:57 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:36:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:36:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:36:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:36:57 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:36:57 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:36:58 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:36:58 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:36:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:36:58 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:38:06 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:38:06 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:38:06 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:38:06 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:38:07 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:38:07 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:38:07 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:38:07 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:38:07 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:38:07 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '本地生活[2]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '搞笑幽默[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '视频音乐[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '旅游[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '校园生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '新闻趣事[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美食[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': 'IT数码[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '宠物[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美图[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '情感生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 90, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 15:38:41 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:38:41 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:38:41 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:38:41 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:38:41 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:38:41 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:38:41 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:38:41 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:38:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:38:41 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '本地生活[2]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '搞笑幽默[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '视频音乐[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '旅游[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '校园生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '新闻趣事[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美食[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': 'IT数码[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '宠物[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美图[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:38:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '情感生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:39:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 90, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 15:39:41 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 24 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:40:19 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:40:19 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:40:19 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:40:19 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:40:20 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:40:20 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:40:20 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:40:20 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:40:20 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:40:20 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '本地生活[2]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '搞笑幽默[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '视频音乐[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '旅游[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '校园生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '新闻趣事[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美食[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': 'IT数码[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '宠物[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美图[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:40:27 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '情感生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 9, in process_item
    print(isinstance(item[0], SinaFansItem))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:08 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:44:08 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:44:08 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:44:08 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:44:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:44:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:44:08 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:44:08 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:44:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:44:08 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '本地生活[2]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '搞笑幽默[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '视频音乐[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '旅游[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '校园生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '新闻趣事[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美食[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': 'IT数码[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '宠物[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美图[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '情感生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 90, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 15:44:43 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:44:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:44:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:44:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:44:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:44:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:44:44 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:44:44 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:44:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:44:44 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '本地生活[2]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '搞笑幽默[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '视频音乐[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '旅游[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '校园生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '新闻趣事[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美食[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': 'IT数码[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '宠物[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美图[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:44:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '情感生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 90, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 15:45:39 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:45:39 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:45:39 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:45:39 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:45:39 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:45:39 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:45:40 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:45:40 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:45:40 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:45:40 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '本地生活[2]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '搞笑幽默[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '视频音乐[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '旅游[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '校园生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '新闻趣事[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美食[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': 'IT数码[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '宠物[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美图[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:45:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '情感生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 90, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 15:46:15 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:46:15 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:46:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:46:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:46:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:46:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:46:16 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:46:16 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:46:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:46:16 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '本地生活[2]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '搞笑幽默[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '视频音乐[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '旅游[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '校园生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '新闻趣事[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美食[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': 'IT数码[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '宠物[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美图[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:46:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '情感生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:27 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:47:27 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:47:27 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:47:27 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:47:28 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:47:28 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:47:28 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:47:28 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:47:28 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:47:28 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '本地生活[2]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '搞笑幽默[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '视频音乐[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '旅游[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '校园生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '新闻趣事[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美食[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': 'IT数码[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '宠物[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '美图[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:47:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836', 'group': '情感生活[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 8, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:49:22 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:49:22 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:49:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:49:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:49:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:49:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:49:23 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:49:23 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:49:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:49:23 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:49:56 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:49:56 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:49:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:49:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:49:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:49:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:49:56 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:49:56 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:49:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:49:57 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:49:57 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:50:23 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:50:23 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:50:23 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:50:23 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:50:23 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:50:23 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:50:23 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:50:23 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:50:23 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:50:23 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:50:23 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:53:01 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:53:01 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:53:01 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:53:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:53:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:53:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:53:01 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:53:01 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:53:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:53:01 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:53:01 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:53:03 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/6068931035',
 'blogger': '5235640836',
 'fansTotal': '粉丝871131人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.640.640.50/006CICcrjw8fbdussmtocj30hs0hswff.jpg',
 'name': '重庆同城'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:03 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5663252702',
 'blogger': '5235640836',
 'fansTotal': '粉丝945302人',
 'headshot': 'http://tva1.sinaimg.cn/crop.2.0.177.177.50/006bgqJwgw1f8vasz3qx2j3050050jrr.jpg',
 'name': '微博泰国'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:03 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/colorrom',
 'blogger': '5235640836',
 'fansTotal': '粉丝3448570人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1277.1277.50/cad206c0ly8fsn6u91tn6j20zh10b7an.jpg',
 'name': 'ColorOS'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:03 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppofind',
 'blogger': '5235640836',
 'fansTotal': '粉丝19289840人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.1080.1080.50/7ad64f97ly8frvfi4kqs0j20u00u0alm.jpg',
 'name': 'OPPO拍照手机'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:03 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppo',
 'blogger': '5235640836',
 'fansTotal': '粉丝25431952人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1080.1080.50/65ef2e69ly8frvfas5ifkj20u00u0alm.jpg',
 'name': 'OPPO'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:03 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1926881397',
 'blogger': '5235640836',
 'fansTotal': '粉丝21158人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.1.1242.1242.50/72d9e075jw8f2x5fsbnx4j20yi0yk771.jpg',
 'name': '岳阳无痕接发盖伦'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:03 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/etjourney',
 'blogger': '5235640836',
 'fansTotal': '粉丝19220人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.101.101.50/006aIh8bjw8f61mc49pfjj302t02twed.jpg',
 'name': '坐享其成官方微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:03 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3662812921',
 'blogger': '5235640836',
 'fansTotal': '粉丝2131人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.512.512.50/da5216f9ly8fphx0pdkndj20e80e8dgb.jpg',
 'name': '岸上的公务员'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:03 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5818851908',
 'blogger': '5235640836',
 'fansTotal': '粉丝30763人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.14.1009.1009.50/006lNjc8ly8fd0dnxjvnsj30sg0sgwix.jpg',
 'name': '唯票上海站'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2680595865',
 'blogger': '5235640836',
 'fansTotal': '粉丝10323人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/9fc6a599jw8f20vus7xzcj20yi0yijuu.jpg',
 'name': '吃货才会爱你'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5249049781',
 'blogger': '5235640836',
 'fansTotal': '粉丝1182人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.960.960.50/005JetDfly8fqmtwdhirpj30qo0qoq49.jpg',
 'name': '长岛冰茶i_'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3496381120',
 'blogger': '5235640836',
 'fansTotal': '粉丝110357人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/d0668ac0jw8f2yxen2vydj20yi0yi40c.jpg',
 'name': '重庆imini婚纱馆'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/huihuixiaochu',
 'blogger': '5235640836',
 'fansTotal': '粉丝99248人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.180.180.50/59402e97jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '烩烩小厨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5355820419',
 'blogger': '5235640836',
 'fansTotal': '粉丝3104人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.749.749.50/005Qstyjly8fisczl2xx1j30ku0kt0u0.jpg',
 'name': '她就是佳琪'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5878675399',
 'blogger': '5235640836',
 'fansTotal': '粉丝54351人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.2.750.750.50/006pQk19jw8f71jsd9qdwj30ku0kzwfo.jpg',
 'name': '菲芝蔓纤体美容-马冬'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806449563',
 'blogger': '5235640836',
 'fansTotal': '粉丝926855人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.512.512.50/a747059bly8fpn89pc0slj20e80e8js8.jpg',
 'name': '美图萌萌酱'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/whymagic',
 'blogger': '5235640836',
 'fansTotal': '粉丝14642人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.180.180.50/69aee3c9jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '神的共犯何志武'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/DZIXY',
 'blogger': '5235640836',
 'fansTotal': '粉丝28781人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.10.492.492.50/e415adbdjw8fczgodeso4j20do0e8q3e.jpg',
 'name': 'DZIXY大嘴小一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:07 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2497371971',
 'blogger': '5235640836',
 'fansTotal': '粉丝98人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.290.290.50/94dadf43jw1f016ekbo3aj2082082dg0.jpg',
 'name': '找船的海盗'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:07 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5651086426',
 'blogger': '5235640836',
 'fansTotal': '粉丝14811人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.996.996.50/006arnJgly8fk78i3xc81j30ro0ro758.jpg',
 'name': '超大番石榴'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:07 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5851065502',
 'blogger': '5235640836',
 'fansTotal': '粉丝54914人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.10.0.730.730.50/006nYtqely8fglnojg970j30ku0kawfo.jpg',
 'name': '僮颜美容咨询师之之'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:07 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/tunable',
 'blogger': '5235640836',
 'fansTotal': '粉丝18460人',
 'headshot': 'http://tva2.sinaimg.cn/crop.588.529.520.520.50/a81f0e7bjw8fcnmm53zhij216o16oayf.jpg',
 'name': 'tunable-jojo美国代购'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:07 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806479950',
 'blogger': '5235640836',
 'fansTotal': '粉丝3794人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1125.1125.50/a7477c4ely8ft7bfrv5gsj20v90v940u.jpg',
 'name': 'AngelicJ71好甜'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:07 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/chbcnet',
 'blogger': '5235640836',
 'fansTotal': '粉丝107183人',
 'headshot': 'http://tva1.sinaimg.cn/crop.6.6.173.173.50/5fb3dbb1gw1eop2ktrznyj2050050aab.jpg',
 'name': '华广网--中国华艺广播公司'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:07 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2940229071',
 'blogger': '5235640836',
 'fansTotal': '粉丝132人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.720.720.50/af4055cfjw8ene1fmpkrtj20k00k0gmp.jpg',
 'name': '思无邪1949'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:53:07 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/benefit',
 'blogger': '5235640836',
 'fansTotal': '粉丝694483人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.180.180.50/69427b8bjw8f12750o8t2j2050050dfq.jpg',
 'name': 'benefit贝玲妃的微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 10, in process_item
    if len(item[0]) == 5:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\item.py", line 59, in __getitem__
    return self._values[key]
KeyError: 0
2018-07-24 15:55:14 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:55:14 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:55:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:55:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:55:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:55:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:55:15 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:55:15 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:55:15 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:55:15 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:55:15 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:55:15 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/6068931035',
 'blogger': '5235640836',
 'fansTotal': '粉丝871131人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.640.640.50/006CICcrjw8fbdussmtocj30hs0hswff.jpg',
 'name': '重庆同城'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    params = (i['blogger'], i['attentionLink'], i['name'], i['fansTotal'], i['headshot'])
TypeError: string indices must be integers
2018-07-24 15:55:15 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5663252702',
 'blogger': '5235640836',
 'fansTotal': '粉丝945302人',
 'headshot': 'http://tva1.sinaimg.cn/crop.2.0.177.177.50/006bgqJwgw1f8vasz3qx2j3050050jrr.jpg',
 'name': '微博泰国'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    params = (i['blogger'], i['attentionLink'], i['name'], i['fansTotal'], i['headshot'])
TypeError: string indices must be integers
2018-07-24 15:55:15 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/colorrom',
 'blogger': '5235640836',
 'fansTotal': '粉丝3448569人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1277.1277.50/cad206c0ly8fsn6u91tn6j20zh10b7an.jpg',
 'name': 'ColorOS'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    params = (i['blogger'], i['attentionLink'], i['name'], i['fansTotal'], i['headshot'])
TypeError: string indices must be integers
2018-07-24 15:55:15 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppofind',
 'blogger': '5235640836',
 'fansTotal': '粉丝19289832人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.1080.1080.50/7ad64f97ly8frvfi4kqs0j20u00u0alm.jpg',
 'name': 'OPPO拍照手机'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    params = (i['blogger'], i['attentionLink'], i['name'], i['fansTotal'], i['headshot'])
TypeError: string indices must be integers
2018-07-24 15:55:15 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppo',
 'blogger': '5235640836',
 'fansTotal': '粉丝25431936人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1080.1080.50/65ef2e69ly8frvfas5ifkj20u00u0alm.jpg',
 'name': 'OPPO'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    params = (i['blogger'], i['attentionLink'], i['name'], i['fansTotal'], i['headshot'])
TypeError: string indices must be integers
2018-07-24 15:55:15 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1926881397',
 'blogger': '5235640836',
 'fansTotal': '粉丝21158人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.1.1242.1242.50/72d9e075jw8f2x5fsbnx4j20yi0yk771.jpg',
 'name': '岳阳无痕接发盖伦'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    params = (i['blogger'], i['attentionLink'], i['name'], i['fansTotal'], i['headshot'])
TypeError: string indices must be integers
2018-07-24 15:55:15 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/etjourney',
 'blogger': '5235640836',
 'fansTotal': '粉丝19220人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.101.101.50/006aIh8bjw8f61mc49pfjj302t02twed.jpg',
 'name': '坐享其成官方微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    params = (i['blogger'], i['attentionLink'], i['name'], i['fansTotal'], i['headshot'])
TypeError: string indices must be integers
2018-07-24 15:55:15 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3662812921',
 'blogger': '5235640836',
 'fansTotal': '粉丝2131人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.512.512.50/da5216f9ly8fphx0pdkndj20e80e8dgb.jpg',
 'name': '岸上的公务员'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    params = (i['blogger'], i['attentionLink'], i['name'], i['fansTotal'], i['headshot'])
TypeError: string indices must be integers
2018-07-24 15:55:15 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5818851908',
 'blogger': '5235640836',
 'fansTotal': '粉丝30763人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.14.1009.1009.50/006lNjc8ly8fd0dnxjvnsj30sg0sgwix.jpg',
 'name': '唯票上海站'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    params = (i['blogger'], i['attentionLink'], i['name'], i['fansTotal'], i['headshot'])
TypeError: string indices must be integers
2018-07-24 15:56:40 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:56:40 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:56:40 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:56:40 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:56:40 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:56:40 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:56:41 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:56:41 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:56:41 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:56:41 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:56:41 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:56:41 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/6068931035',
 'blogger': '5235640836',
 'fansTotal': '粉丝871131人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.640.640.50/006CICcrjw8fbdussmtocj30hs0hswff.jpg',
 'name': '重庆同城'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5663252702',
 'blogger': '5235640836',
 'fansTotal': '粉丝945302人',
 'headshot': 'http://tva1.sinaimg.cn/crop.2.0.177.177.50/006bgqJwgw1f8vasz3qx2j3050050jrr.jpg',
 'name': '微博泰国'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/colorrom',
 'blogger': '5235640836',
 'fansTotal': '粉丝3448569人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1277.1277.50/cad206c0ly8fsn6u91tn6j20zh10b7an.jpg',
 'name': 'ColorOS'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppofind',
 'blogger': '5235640836',
 'fansTotal': '粉丝19289826人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.1080.1080.50/7ad64f97ly8frvfi4kqs0j20u00u0alm.jpg',
 'name': 'OPPO拍照手机'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppo',
 'blogger': '5235640836',
 'fansTotal': '粉丝25431933人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1080.1080.50/65ef2e69ly8frvfas5ifkj20u00u0alm.jpg',
 'name': 'OPPO'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1926881397',
 'blogger': '5235640836',
 'fansTotal': '粉丝21158人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.1.1242.1242.50/72d9e075jw8f2x5fsbnx4j20yi0yk771.jpg',
 'name': '岳阳无痕接发盖伦'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/etjourney',
 'blogger': '5235640836',
 'fansTotal': '粉丝19220人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.101.101.50/006aIh8bjw8f61mc49pfjj302t02twed.jpg',
 'name': '坐享其成官方微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3662812921',
 'blogger': '5235640836',
 'fansTotal': '粉丝2131人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.512.512.50/da5216f9ly8fphx0pdkndj20e80e8dgb.jpg',
 'name': '岸上的公务员'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5818851908',
 'blogger': '5235640836',
 'fansTotal': '粉丝30763人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.14.1009.1009.50/006lNjc8ly8fd0dnxjvnsj30sg0sgwix.jpg',
 'name': '唯票上海站'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:43 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2680595865',
 'blogger': '5235640836',
 'fansTotal': '粉丝10323人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/9fc6a599jw8f20vus7xzcj20yi0yijuu.jpg',
 'name': '吃货才会爱你'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:43 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5249049781',
 'blogger': '5235640836',
 'fansTotal': '粉丝1182人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.960.960.50/005JetDfly8fqmtwdhirpj30qo0qoq49.jpg',
 'name': '长岛冰茶i_'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:43 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3496381120',
 'blogger': '5235640836',
 'fansTotal': '粉丝110357人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/d0668ac0jw8f2yxen2vydj20yi0yi40c.jpg',
 'name': '重庆imini婚纱馆'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:43 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/huihuixiaochu',
 'blogger': '5235640836',
 'fansTotal': '粉丝99248人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.180.180.50/59402e97jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '烩烩小厨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:43 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5355820419',
 'blogger': '5235640836',
 'fansTotal': '粉丝3104人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.749.749.50/005Qstyjly8fisczl2xx1j30ku0kt0u0.jpg',
 'name': '她就是佳琪'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:43 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5878675399',
 'blogger': '5235640836',
 'fansTotal': '粉丝54351人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.2.750.750.50/006pQk19jw8f71jsd9qdwj30ku0kzwfo.jpg',
 'name': '菲芝蔓纤体美容-马冬'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:43 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806449563',
 'blogger': '5235640836',
 'fansTotal': '粉丝926855人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.512.512.50/a747059bly8fpn89pc0slj20e80e8js8.jpg',
 'name': '美图萌萌酱'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:43 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/whymagic',
 'blogger': '5235640836',
 'fansTotal': '粉丝14642人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.180.180.50/69aee3c9jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '神的共犯何志武'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:43 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/DZIXY',
 'blogger': '5235640836',
 'fansTotal': '粉丝28781人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.10.492.492.50/e415adbdjw8fczgodeso4j20do0e8q3e.jpg',
 'name': 'DZIXY大嘴小一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:46 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2497371971',
 'blogger': '5235640836',
 'fansTotal': '粉丝98人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.290.290.50/94dadf43jw1f016ekbo3aj2082082dg0.jpg',
 'name': '找船的海盗'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:46 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5651086426',
 'blogger': '5235640836',
 'fansTotal': '粉丝14811人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.996.996.50/006arnJgly8fk78i3xc81j30ro0ro758.jpg',
 'name': '超大番石榴'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:46 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5851065502',
 'blogger': '5235640836',
 'fansTotal': '粉丝54914人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.10.0.730.730.50/006nYtqely8fglnojg970j30ku0kawfo.jpg',
 'name': '僮颜美容咨询师之之'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/tunable',
 'blogger': '5235640836',
 'fansTotal': '粉丝18460人',
 'headshot': 'http://tva2.sinaimg.cn/crop.588.529.520.520.50/a81f0e7bjw8fcnmm53zhij216o16oayf.jpg',
 'name': 'tunable-jojo美国代购'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806479950',
 'blogger': '5235640836',
 'fansTotal': '粉丝3794人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1125.1125.50/a7477c4ely8ft7bfrv5gsj20v90v940u.jpg',
 'name': 'AngelicJ71好甜'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/chbcnet',
 'blogger': '5235640836',
 'fansTotal': '粉丝107183人',
 'headshot': 'http://tva1.sinaimg.cn/crop.6.6.173.173.50/5fb3dbb1gw1eop2ktrznyj2050050aab.jpg',
 'name': '华广网--中国华艺广播公司'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2940229071',
 'blogger': '5235640836',
 'fansTotal': '粉丝132人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.720.720.50/af4055cfjw8ene1fmpkrtj20k00k0gmp.jpg',
 'name': '思无邪1949'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:56:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/benefit',
 'blogger': '5235640836',
 'fansTotal': '粉丝694483人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.180.180.50/69427b8bjw8f12750o8t2j2050050dfq.jpg',
 'name': 'benefit贝玲妃的微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql,params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:07 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:57:07 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:57:07 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:57:07 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:57:08 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:57:08 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:57:08 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:57:08 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:57:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:57:08 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:57:08 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:57:32 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:57:32 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:57:32 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:57:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:57:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:57:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:57:33 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:57:33 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:57:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:57:33 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:57:33 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:57:55 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/6068931035',
 'blogger': '5235640836',
 'fansTotal': '粉丝871131人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.640.640.50/006CICcrjw8fbdussmtocj30hs0hswff.jpg',
 'name': '重庆同城'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:55 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5663252702',
 'blogger': '5235640836',
 'fansTotal': '粉丝945302人',
 'headshot': 'http://tva1.sinaimg.cn/crop.2.0.177.177.50/006bgqJwgw1f8vasz3qx2j3050050jrr.jpg',
 'name': '微博泰国'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:55 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/colorrom',
 'blogger': '5235640836',
 'fansTotal': '粉丝3448568人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1277.1277.50/cad206c0ly8fsn6u91tn6j20zh10b7an.jpg',
 'name': 'ColorOS'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:55 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppofind',
 'blogger': '5235640836',
 'fansTotal': '粉丝19289824人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.1080.1080.50/7ad64f97ly8frvfi4kqs0j20u00u0alm.jpg',
 'name': 'OPPO拍照手机'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:55 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppo',
 'blogger': '5235640836',
 'fansTotal': '粉丝25431929人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1080.1080.50/65ef2e69ly8frvfas5ifkj20u00u0alm.jpg',
 'name': 'OPPO'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:55 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1926881397',
 'blogger': '5235640836',
 'fansTotal': '粉丝21158人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.1.1242.1242.50/72d9e075jw8f2x5fsbnx4j20yi0yk771.jpg',
 'name': '岳阳无痕接发盖伦'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:55 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/etjourney',
 'blogger': '5235640836',
 'fansTotal': '粉丝19220人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.101.101.50/006aIh8bjw8f61mc49pfjj302t02twed.jpg',
 'name': '坐享其成官方微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:55 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3662812921',
 'blogger': '5235640836',
 'fansTotal': '粉丝2131人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.512.512.50/da5216f9ly8fphx0pdkndj20e80e8dgb.jpg',
 'name': '岸上的公务员'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:55 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5818851908',
 'blogger': '5235640836',
 'fansTotal': '粉丝30763人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.14.1009.1009.50/006lNjc8ly8fd0dnxjvnsj30sg0sgwix.jpg',
 'name': '唯票上海站'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:57 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2680595865',
 'blogger': '5235640836',
 'fansTotal': '粉丝10323人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/9fc6a599jw8f20vus7xzcj20yi0yijuu.jpg',
 'name': '吃货才会爱你'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:57 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5249049781',
 'blogger': '5235640836',
 'fansTotal': '粉丝1182人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.960.960.50/005JetDfly8fqmtwdhirpj30qo0qoq49.jpg',
 'name': '长岛冰茶i_'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:57 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3496381120',
 'blogger': '5235640836',
 'fansTotal': '粉丝110357人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/d0668ac0jw8f2yxen2vydj20yi0yi40c.jpg',
 'name': '重庆imini婚纱馆'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:57 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/huihuixiaochu',
 'blogger': '5235640836',
 'fansTotal': '粉丝99248人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.180.180.50/59402e97jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '烩烩小厨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:57 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5355820419',
 'blogger': '5235640836',
 'fansTotal': '粉丝3104人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.749.749.50/005Qstyjly8fisczl2xx1j30ku0kt0u0.jpg',
 'name': '她就是佳琪'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:57 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5878675399',
 'blogger': '5235640836',
 'fansTotal': '粉丝54351人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.2.750.750.50/006pQk19jw8f71jsd9qdwj30ku0kzwfo.jpg',
 'name': '菲芝蔓纤体美容-马冬'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:57 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806449563',
 'blogger': '5235640836',
 'fansTotal': '粉丝926855人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.512.512.50/a747059bly8fpn89pc0slj20e80e8js8.jpg',
 'name': '美图萌萌酱'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:57 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/whymagic',
 'blogger': '5235640836',
 'fansTotal': '粉丝14642人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.180.180.50/69aee3c9jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '神的共犯何志武'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:57:57 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/DZIXY',
 'blogger': '5235640836',
 'fansTotal': '粉丝28781人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.10.492.492.50/e415adbdjw8fczgodeso4j20do0e8q3e.jpg',
 'name': 'DZIXY大嘴小一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:00 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2497371971',
 'blogger': '5235640836',
 'fansTotal': '粉丝98人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.290.290.50/94dadf43jw1f016ekbo3aj2082082dg0.jpg',
 'name': '找船的海盗'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:00 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5651086426',
 'blogger': '5235640836',
 'fansTotal': '粉丝14811人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.996.996.50/006arnJgly8fk78i3xc81j30ro0ro758.jpg',
 'name': '超大番石榴'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:00 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5851065502',
 'blogger': '5235640836',
 'fansTotal': '粉丝54914人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.10.0.730.730.50/006nYtqely8fglnojg970j30ku0kawfo.jpg',
 'name': '僮颜美容咨询师之之'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:00 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/tunable',
 'blogger': '5235640836',
 'fansTotal': '粉丝18460人',
 'headshot': 'http://tva2.sinaimg.cn/crop.588.529.520.520.50/a81f0e7bjw8fcnmm53zhij216o16oayf.jpg',
 'name': 'tunable-jojo美国代购'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:00 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806479950',
 'blogger': '5235640836',
 'fansTotal': '粉丝3794人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1125.1125.50/a7477c4ely8ft7bfrv5gsj20v90v940u.jpg',
 'name': 'AngelicJ71好甜'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:00 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/chbcnet',
 'blogger': '5235640836',
 'fansTotal': '粉丝107183人',
 'headshot': 'http://tva1.sinaimg.cn/crop.6.6.173.173.50/5fb3dbb1gw1eop2ktrznyj2050050aab.jpg',
 'name': '华广网--中国华艺广播公司'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:00 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2940229071',
 'blogger': '5235640836',
 'fansTotal': '粉丝132人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.720.720.50/af4055cfjw8ene1fmpkrtj20k00k0gmp.jpg',
 'name': '思无邪1949'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:00 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/benefit',
 'blogger': '5235640836',
 'fansTotal': '粉丝694483人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.180.180.50/69427b8bjw8f12750o8t2j2050050dfq.jpg',
 'name': 'benefit贝玲妃的微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3244159200',
 'blogger': '5235640836',
 'fansTotal': '粉丝23669人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.1242.1242.50/c15df0e0jw8f6v451kq1ej20yi0yijum.jpg',
 'name': 'A_夏雨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5782475631',
 'blogger': '5235640836',
 'fansTotal': '粉丝2197人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.996.996.50/006jkG3Zly8frmab27aamj30ro0rodhq.jpg',
 'name': '就是Duan阿duan'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3691964202',
 'blogger': '5235640836',
 'fansTotal': '粉丝20005人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.750.750.50/dc0ee72aly8fia1m8r4otj20ku0kut9w.jpg',
 'name': '我是歪牙'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2402983764',
 'blogger': '5235640836',
 'fansTotal': '粉丝2645人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.17.111.684.684.50/8f3a9f54ly8fgm9vk7pkqj20m80m8n7k.jpg',
 'name': '盈丰专业灯牌订制厂家'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5043828015',
 'blogger': '5235640836',
 'fansTotal': '粉丝632人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.512.512.50/005vlo4Lly8fm1dvwekqlj30e80e8q43.jpg',
 'name': 'APing98'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/ping136690482',
 'blogger': '5235640836',
 'fansTotal': '粉丝10028人',
 'headshot': 'http://tva3.sinaimg.cn/crop.37.21.384.384.50/006aXirIjw1f1rs00kwswj30di0ht0v5.jpg',
 'name': '泽莹老师'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5237190151',
 'blogger': '5235640836',
 'fansTotal': '粉丝2581人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.0.750.750.50/005IqIoTly8fsxjimjvbuj30ku0kut9b.jpg',
 'name': 'Mr蜡笔先生'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/perfectidphoto',
 'blogger': '5235640836',
 'fansTotal': '粉丝3043人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.0.750.750.50/0061uBzNjw8f3hhjkl5xzj30ku0ku0t2.jpg',
 'name': '完美证照'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3205374414',
 'blogger': '5235640836',
 'fansTotal': '粉丝1293人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.996.996.50/bf0e21cejw8f6hvwzf5mtj20ro0rpgow.jpg',
 'name': 'AJun姜姜'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:02 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1308391574',
 'blogger': '5235640836',
 'fansTotal': '粉丝1295925人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.1125.1125.50/4dfc7896ly8ft6rkkonyvj20v90v975s.jpg',
 'name': '高瀚宇KD'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5884259049',
 'blogger': '5235640836',
 'fansTotal': '粉丝1032人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.512.512.50/006qdKA1jw8f1z1juw0nbj30e80e8mxk.jpg',
 'name': '星妈0130'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5244040548',
 'blogger': '5235640836',
 'fansTotal': '粉丝12073人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/005ITsvajw8f3w7r0duzpj30yi0yjjz3.jpg',
 'name': 'lonely碗'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/samlee221',
 'blogger': '5235640836',
 'fansTotal': '粉丝1085989人',
 'headshot': 'http://tva2.sinaimg.cn/crop.2.0.797.797.50/68e4dd93jw8eytk5cto8gj20m80m810c.jpg',
 'name': '歌手李圣杰'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5073632657',
 'blogger': '5235640836',
 'fansTotal': '粉丝212853人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.0.996.996.50/005xmrCNjw8f0kauzkioej30ro0rodgq.jpg',
 'name': '万年奔波儿灞'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/chinaphilipstvc219',
 'blogger': '5235640836',
 'fansTotal': '粉丝887969人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.69.74.428.428.50/9f6cd689ly8fh94gr96nzj20fr0frn1c.jpg',
 'name': '飞利浦电视'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2961021294',
 'blogger': '5235640836',
 'fansTotal': '粉丝1866人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.1125.1125.50/b07d996ely8fpfdkyu0tkj20v90v9wgz.jpg',
 'name': '野生的象'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5780565993',
 'blogger': '5235640836',
 'fansTotal': '粉丝11338人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.0.1556.1556.50/006jcFhnjw1f4ldqf7slfj31781780yh.jpg',
 'name': '鹰视社'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3163880702',
 'blogger': '5235640836',
 'fansTotal': '粉丝3166人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.9.493.493.50/bc94fcfely8flauyepa6nj20dp0e8t92.jpg',
 'name': '算卦半仙我姓杨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5794206727',
 'blogger': '5235640836',
 'fansTotal': '粉丝3594人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.499.499.50/006k7TRdgw1ez20ynvhlrj30dw0dw74z.jpg',
 'name': '克丝可清个人洗护品牌'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:05 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2994078362',
 'blogger': '5235640836',
 'fansTotal': '粉丝2266人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.996.996.50/b276029ajw8fczojzfs4uj20ro0rpq53.jpg',
 'name': '清霜溯雪'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5829330757',
 'blogger': '5235640836',
 'fansTotal': '粉丝10691人',
 'headshot': 'http://tva3.sinaimg.cn/crop.21.19.168.168.50/006mvhdPjw8f2lm63h0xhj305w05v3z4.jpg',
 'name': '陆拾伍商城'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5881902986',
 'blogger': '5235640836',
 'fansTotal': '粉丝5012人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.1242.1242.50/006q3RF0jw8f1xm4sio5lj30yi0yiq41.jpg',
 'name': 'Freshmix长沙'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5453958770',
 'blogger': '5235640836',
 'fansTotal': '粉丝31245人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.512.512.50/005X6fOWjw8f5ce7zxvexj30e80e8jrs.jpg',
 'name': '_沈芊伊'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5867657265',
 'blogger': '5235640836',
 'fansTotal': '粉丝66134人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.512.512.50/006p65Hjjw8fa8436scc6j30e80e8jrz.jpg',
 'name': '深圳瑞思国际半永久皮肤管理'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3157917407',
 'blogger': '5235640836',
 'fansTotal': '粉丝8527人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.749.749.50/bc39fedfly8fm3m79c4fqj20ku0kt763.jpg',
 'name': '丁怡DINGYI'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5627767465',
 'blogger': '5235640836',
 'fansTotal': '粉丝966712人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.27.0.335.335.50/0068RxoZly8fm1jh687dvj30aa09b752.jpg',
 'name': '赏味期限'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1050398682',
 'blogger': '5235640836',
 'fansTotal': '粉丝1723人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.0.1125.1125.50/3e9bcfdaly8fsxomk9ghzj20v90v90tx.jpg',
 'name': '叶峻宏Elijah'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2561778622',
 'blogger': '5235640836',
 'fansTotal': '粉丝98333人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.512.512.50/98b1a3bely8fq2iugx60fj20e80e8dfz.jpg',
 'name': 'SOCO江铭'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1808294677',
 'blogger': '5235640836',
 'fansTotal': '粉丝372人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.0.512.512.50/6bc86315jw8f1rlz1349uj20e80e874t.jpg',
 'name': '仓游'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:58:08 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5747057854',
 'blogger': '5235640836',
 'fansTotal': '粉丝1360人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.15.0.1212.1212.50/006gW4hwly8fjasvwab38j30yi0xoq67.jpg',
 'name': '万花瞳乐队'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:43 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 15:59:43 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 15:59:43 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 15:59:43 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 15:59:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 15:59:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 15:59:44 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 15:59:44 [scrapy.core.engine] INFO: Spider opened
2018-07-24 15:59:44 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 15:59:44 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:59:44 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 15:59:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/6068931035',
 'blogger': '5235640836',
 'fansTotal': '粉丝871131人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.640.640.50/006CICcrjw8fbdussmtocj30hs0hswff.jpg',
 'name': '重庆同城'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5663252702',
 'blogger': '5235640836',
 'fansTotal': '粉丝945302人',
 'headshot': 'http://tva1.sinaimg.cn/crop.2.0.177.177.50/006bgqJwgw1f8vasz3qx2j3050050jrr.jpg',
 'name': '微博泰国'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/colorrom',
 'blogger': '5235640836',
 'fansTotal': '粉丝3448569人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1277.1277.50/cad206c0ly8fsn6u91tn6j20zh10b7an.jpg',
 'name': 'ColorOS'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppofind',
 'blogger': '5235640836',
 'fansTotal': '粉丝19289818人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.1080.1080.50/7ad64f97ly8frvfi4kqs0j20u00u0alm.jpg',
 'name': 'OPPO拍照手机'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppo',
 'blogger': '5235640836',
 'fansTotal': '粉丝25431926人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1080.1080.50/65ef2e69ly8frvfas5ifkj20u00u0alm.jpg',
 'name': 'OPPO'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1926881397',
 'blogger': '5235640836',
 'fansTotal': '粉丝21158人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.1.1242.1242.50/72d9e075jw8f2x5fsbnx4j20yi0yk771.jpg',
 'name': '岳阳无痕接发盖伦'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/etjourney',
 'blogger': '5235640836',
 'fansTotal': '粉丝19220人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.101.101.50/006aIh8bjw8f61mc49pfjj302t02twed.jpg',
 'name': '坐享其成官方微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3662812921',
 'blogger': '5235640836',
 'fansTotal': '粉丝2131人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.512.512.50/da5216f9ly8fphx0pdkndj20e80e8dgb.jpg',
 'name': '岸上的公务员'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5818851908',
 'blogger': '5235640836',
 'fansTotal': '粉丝30763人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.14.1009.1009.50/006lNjc8ly8fd0dnxjvnsj30sg0sgwix.jpg',
 'name': '唯票上海站'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2680595865',
 'blogger': '5235640836',
 'fansTotal': '粉丝10323人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/9fc6a599jw8f20vus7xzcj20yi0yijuu.jpg',
 'name': '吃货才会爱你'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5249049781',
 'blogger': '5235640836',
 'fansTotal': '粉丝1182人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.960.960.50/005JetDfly8fqmtwdhirpj30qo0qoq49.jpg',
 'name': '长岛冰茶i_'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3496381120',
 'blogger': '5235640836',
 'fansTotal': '粉丝110357人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/d0668ac0jw8f2yxen2vydj20yi0yi40c.jpg',
 'name': '重庆imini婚纱馆'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/huihuixiaochu',
 'blogger': '5235640836',
 'fansTotal': '粉丝99248人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.180.180.50/59402e97jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '烩烩小厨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5355820419',
 'blogger': '5235640836',
 'fansTotal': '粉丝3104人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.749.749.50/005Qstyjly8fisczl2xx1j30ku0kt0u0.jpg',
 'name': '她就是佳琪'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5878675399',
 'blogger': '5235640836',
 'fansTotal': '粉丝54351人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.2.750.750.50/006pQk19jw8f71jsd9qdwj30ku0kzwfo.jpg',
 'name': '菲芝蔓纤体美容-马冬'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806449563',
 'blogger': '5235640836',
 'fansTotal': '粉丝926855人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.512.512.50/a747059bly8fpn89pc0slj20e80e8js8.jpg',
 'name': '美图萌萌酱'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/whymagic',
 'blogger': '5235640836',
 'fansTotal': '粉丝14642人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.180.180.50/69aee3c9jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '神的共犯何志武'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 15:59:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/DZIXY',
 'blogger': '5235640836',
 'fansTotal': '粉丝28781人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.10.492.492.50/e415adbdjw8fczgodeso4j20do0e8q3e.jpg',
 'name': 'DZIXY大嘴小一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 14, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '%s,%s,%s,%s,%s)' at line 1")
2018-07-24 16:04:26 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:04:26 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:04:26 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:04:26 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:04:27 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:04:27 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:04:27 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:04:27 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:04:27 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:04:27 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:04:27 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:04:28 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/6068931035',
 'blogger': '5235640836',
 'fansTotal': '粉丝871131人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.640.640.50/006CICcrjw8fbdussmtocj30hs0hswff.jpg',
 'name': '重庆同城'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝871131人' for column 'fansTotal' at row 1")
2018-07-24 16:04:28 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5663252702',
 'blogger': '5235640836',
 'fansTotal': '粉丝945302人',
 'headshot': 'http://tva1.sinaimg.cn/crop.2.0.177.177.50/006bgqJwgw1f8vasz3qx2j3050050jrr.jpg',
 'name': '微博泰国'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝945302人' for column 'fansTotal' at row 1")
2018-07-24 16:04:28 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/colorrom',
 'blogger': '5235640836',
 'fansTotal': '粉丝3448569人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1277.1277.50/cad206c0ly8fsn6u91tn6j20zh10b7an.jpg',
 'name': 'ColorOS'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3448569人' for column 'fansTotal' at row 1")
2018-07-24 16:04:28 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppofind',
 'blogger': '5235640836',
 'fansTotal': '粉丝19289807人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.1080.1080.50/7ad64f97ly8frvfi4kqs0j20u00u0alm.jpg',
 'name': 'OPPO拍照手机'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝19289807人' for column 'fansTotal' at row 1")
2018-07-24 16:04:28 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppo',
 'blogger': '5235640836',
 'fansTotal': '粉丝25431914人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1080.1080.50/65ef2e69ly8frvfas5ifkj20u00u0alm.jpg',
 'name': 'OPPO'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝25431914人' for column 'fansTotal' at row 1")
2018-07-24 16:04:28 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1926881397',
 'blogger': '5235640836',
 'fansTotal': '粉丝21158人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.1.1242.1242.50/72d9e075jw8f2x5fsbnx4j20yi0yk771.jpg',
 'name': '岳阳无痕接发盖伦'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝21158人' for column 'fansTotal' at row 1")
2018-07-24 16:04:28 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/etjourney',
 'blogger': '5235640836',
 'fansTotal': '粉丝19220人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.101.101.50/006aIh8bjw8f61mc49pfjj302t02twed.jpg',
 'name': '坐享其成官方微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝19220人' for column 'fansTotal' at row 1")
2018-07-24 16:04:28 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3662812921',
 'blogger': '5235640836',
 'fansTotal': '粉丝2131人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.512.512.50/da5216f9ly8fphx0pdkndj20e80e8dgb.jpg',
 'name': '岸上的公务员'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝2131人' for column 'fansTotal' at row 1")
2018-07-24 16:04:28 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5818851908',
 'blogger': '5235640836',
 'fansTotal': '粉丝30763人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.14.1009.1009.50/006lNjc8ly8fd0dnxjvnsj30sg0sgwix.jpg',
 'name': '唯票上海站'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝30763人' for column 'fansTotal' at row 1")
2018-07-24 16:04:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2680595865',
 'blogger': '5235640836',
 'fansTotal': '粉丝10323人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/9fc6a599jw8f20vus7xzcj20yi0yijuu.jpg',
 'name': '吃货才会爱你'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝10323人' for column 'fansTotal' at row 1")
2018-07-24 16:04:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5249049781',
 'blogger': '5235640836',
 'fansTotal': '粉丝1182人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.960.960.50/005JetDfly8fqmtwdhirpj30qo0qoq49.jpg',
 'name': '长岛冰茶i_'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝1182人' for column 'fansTotal' at row 1")
2018-07-24 16:04:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3496381120',
 'blogger': '5235640836',
 'fansTotal': '粉丝110357人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/d0668ac0jw8f2yxen2vydj20yi0yi40c.jpg',
 'name': '重庆imini婚纱馆'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝110357人' for column 'fansTotal' at row 1")
2018-07-24 16:04:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/huihuixiaochu',
 'blogger': '5235640836',
 'fansTotal': '粉丝99248人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.180.180.50/59402e97jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '烩烩小厨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝99248人' for column 'fansTotal' at row 1")
2018-07-24 16:04:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5355820419',
 'blogger': '5235640836',
 'fansTotal': '粉丝3104人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.749.749.50/005Qstyjly8fisczl2xx1j30ku0kt0u0.jpg',
 'name': '她就是佳琪'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3104人' for column 'fansTotal' at row 1")
2018-07-24 16:04:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5878675399',
 'blogger': '5235640836',
 'fansTotal': '粉丝54351人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.2.750.750.50/006pQk19jw8f71jsd9qdwj30ku0kzwfo.jpg',
 'name': '菲芝蔓纤体美容-马冬'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝54351人' for column 'fansTotal' at row 1")
2018-07-24 16:04:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806449563',
 'blogger': '5235640836',
 'fansTotal': '粉丝926855人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.512.512.50/a747059bly8fpn89pc0slj20e80e8js8.jpg',
 'name': '美图萌萌酱'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝926855人' for column 'fansTotal' at row 1")
2018-07-24 16:04:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/whymagic',
 'blogger': '5235640836',
 'fansTotal': '粉丝14642人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.180.180.50/69aee3c9jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '神的共犯何志武'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝14642人' for column 'fansTotal' at row 1")
2018-07-24 16:04:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/DZIXY',
 'blogger': '5235640836',
 'fansTotal': '粉丝28781人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.10.492.492.50/e415adbdjw8fczgodeso4j20do0e8q3e.jpg',
 'name': 'DZIXY大嘴小一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝28781人' for column 'fansTotal' at row 1")
2018-07-24 16:04:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2497371971',
 'blogger': '5235640836',
 'fansTotal': '粉丝98人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.290.290.50/94dadf43jw1f016ekbo3aj2082082dg0.jpg',
 'name': '找船的海盗'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝98人' for column 'fansTotal' at row 1")
2018-07-24 16:04:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5651086426',
 'blogger': '5235640836',
 'fansTotal': '粉丝14811人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.996.996.50/006arnJgly8fk78i3xc81j30ro0ro758.jpg',
 'name': '超大番石榴'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝14811人' for column 'fansTotal' at row 1")
2018-07-24 16:04:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5851065502',
 'blogger': '5235640836',
 'fansTotal': '粉丝54914人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.10.0.730.730.50/006nYtqely8fglnojg970j30ku0kawfo.jpg',
 'name': '僮颜美容咨询师之之'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝54914人' for column 'fansTotal' at row 1")
2018-07-24 16:04:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/tunable',
 'blogger': '5235640836',
 'fansTotal': '粉丝18460人',
 'headshot': 'http://tva2.sinaimg.cn/crop.588.529.520.520.50/a81f0e7bjw8fcnmm53zhij216o16oayf.jpg',
 'name': 'tunable-jojo美国代购'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝18460人' for column 'fansTotal' at row 1")
2018-07-24 16:04:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806479950',
 'blogger': '5235640836',
 'fansTotal': '粉丝3794人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1125.1125.50/a7477c4ely8ft7bfrv5gsj20v90v940u.jpg',
 'name': 'AngelicJ71好甜'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3794人' for column 'fansTotal' at row 1")
2018-07-24 16:04:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/chbcnet',
 'blogger': '5235640836',
 'fansTotal': '粉丝107183人',
 'headshot': 'http://tva1.sinaimg.cn/crop.6.6.173.173.50/5fb3dbb1gw1eop2ktrznyj2050050aab.jpg',
 'name': '华广网--中国华艺广播公司'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝107183人' for column 'fansTotal' at row 1")
2018-07-24 16:04:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2940229071',
 'blogger': '5235640836',
 'fansTotal': '粉丝132人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.720.720.50/af4055cfjw8ene1fmpkrtj20k00k0gmp.jpg',
 'name': '思无邪1949'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝132人' for column 'fansTotal' at row 1")
2018-07-24 16:04:44 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/benefit',
 'blogger': '5235640836',
 'fansTotal': '粉丝694483人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.180.180.50/69427b8bjw8f12750o8t2j2050050dfq.jpg',
 'name': 'benefit贝玲妃的微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝694483人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3244159200',
 'blogger': '5235640836',
 'fansTotal': '粉丝23669人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.1242.1242.50/c15df0e0jw8f6v451kq1ej20yi0yijum.jpg',
 'name': 'A_夏雨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝23669人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5782475631',
 'blogger': '5235640836',
 'fansTotal': '粉丝2197人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.996.996.50/006jkG3Zly8frmab27aamj30ro0rodhq.jpg',
 'name': '就是Duan阿duan'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝2197人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3691964202',
 'blogger': '5235640836',
 'fansTotal': '粉丝20005人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.750.750.50/dc0ee72aly8fia1m8r4otj20ku0kut9w.jpg',
 'name': '我是歪牙'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝20005人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2402983764',
 'blogger': '5235640836',
 'fansTotal': '粉丝2645人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.17.111.684.684.50/8f3a9f54ly8fgm9vk7pkqj20m80m8n7k.jpg',
 'name': '盈丰专业灯牌订制厂家'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝2645人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5043828015',
 'blogger': '5235640836',
 'fansTotal': '粉丝632人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.512.512.50/005vlo4Lly8fm1dvwekqlj30e80e8q43.jpg',
 'name': 'APing98'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝632人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/ping136690482',
 'blogger': '5235640836',
 'fansTotal': '粉丝10028人',
 'headshot': 'http://tva3.sinaimg.cn/crop.37.21.384.384.50/006aXirIjw1f1rs00kwswj30di0ht0v5.jpg',
 'name': '泽莹老师'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝10028人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5237190151',
 'blogger': '5235640836',
 'fansTotal': '粉丝2581人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.0.750.750.50/005IqIoTly8fsxjimjvbuj30ku0kut9b.jpg',
 'name': 'Mr蜡笔先生'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝2581人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/perfectidphoto',
 'blogger': '5235640836',
 'fansTotal': '粉丝3043人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.0.750.750.50/0061uBzNjw8f3hhjkl5xzj30ku0ku0t2.jpg',
 'name': '完美证照'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3043人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3205374414',
 'blogger': '5235640836',
 'fansTotal': '粉丝1293人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.996.996.50/bf0e21cejw8f6hvwzf5mtj20ro0rpgow.jpg',
 'name': 'AJun姜姜'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝1293人' for column 'fansTotal' at row 1")
2018-07-24 16:04:51 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1308391574',
 'blogger': '5235640836',
 'fansTotal': '粉丝1296172人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.1125.1125.50/4dfc7896ly8ft6rkkonyvj20v90v975s.jpg',
 'name': '高瀚宇KD'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 12, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝1296172人' for column 'fansTotal' at row 1")
2018-07-24 16:04:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 88, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:05:05 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:05:05 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:05:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:05:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:05:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:05:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:05:05 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:05:05 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:05:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:05:05 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:05:05 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:05:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 88, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:05:29 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/6068931035',
 'blogger': '5235640836',
 'fansTotal': '粉丝871131人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.640.640.50/006CICcrjw8fbdussmtocj30hs0hswff.jpg',
 'name': '重庆同城'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝871131人' for column 'fansTotal' at row 1")
2018-07-24 16:05:29 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5663252702',
 'blogger': '5235640836',
 'fansTotal': '粉丝945302人',
 'headshot': 'http://tva1.sinaimg.cn/crop.2.0.177.177.50/006bgqJwgw1f8vasz3qx2j3050050jrr.jpg',
 'name': '微博泰国'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝945302人' for column 'fansTotal' at row 1")
2018-07-24 16:05:29 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/colorrom',
 'blogger': '5235640836',
 'fansTotal': '粉丝3448569人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1277.1277.50/cad206c0ly8fsn6u91tn6j20zh10b7an.jpg',
 'name': 'ColorOS'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3448569人' for column 'fansTotal' at row 1")
2018-07-24 16:05:29 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppofind',
 'blogger': '5235640836',
 'fansTotal': '粉丝19289801人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.1080.1080.50/7ad64f97ly8frvfi4kqs0j20u00u0alm.jpg',
 'name': 'OPPO拍照手机'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝19289801人' for column 'fansTotal' at row 1")
2018-07-24 16:05:29 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/oppo',
 'blogger': '5235640836',
 'fansTotal': '粉丝25431910人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1080.1080.50/65ef2e69ly8frvfas5ifkj20u00u0alm.jpg',
 'name': 'OPPO'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝25431910人' for column 'fansTotal' at row 1")
2018-07-24 16:05:29 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1926881397',
 'blogger': '5235640836',
 'fansTotal': '粉丝21158人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.1.1242.1242.50/72d9e075jw8f2x5fsbnx4j20yi0yk771.jpg',
 'name': '岳阳无痕接发盖伦'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝21158人' for column 'fansTotal' at row 1")
2018-07-24 16:05:29 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/etjourney',
 'blogger': '5235640836',
 'fansTotal': '粉丝19220人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.101.101.50/006aIh8bjw8f61mc49pfjj302t02twed.jpg',
 'name': '坐享其成官方微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝19220人' for column 'fansTotal' at row 1")
2018-07-24 16:05:29 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3662812921',
 'blogger': '5235640836',
 'fansTotal': '粉丝2131人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.512.512.50/da5216f9ly8fphx0pdkndj20e80e8dgb.jpg',
 'name': '岸上的公务员'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝2131人' for column 'fansTotal' at row 1")
2018-07-24 16:05:29 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5818851908',
 'blogger': '5235640836',
 'fansTotal': '粉丝30763人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.14.1009.1009.50/006lNjc8ly8fd0dnxjvnsj30sg0sgwix.jpg',
 'name': '唯票上海站'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝30763人' for column 'fansTotal' at row 1")
2018-07-24 16:05:34 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2680595865',
 'blogger': '5235640836',
 'fansTotal': '粉丝10323人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/9fc6a599jw8f20vus7xzcj20yi0yijuu.jpg',
 'name': '吃货才会爱你'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝10323人' for column 'fansTotal' at row 1")
2018-07-24 16:05:34 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5249049781',
 'blogger': '5235640836',
 'fansTotal': '粉丝1182人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.960.960.50/005JetDfly8fqmtwdhirpj30qo0qoq49.jpg',
 'name': '长岛冰茶i_'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝1182人' for column 'fansTotal' at row 1")
2018-07-24 16:05:34 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3496381120',
 'blogger': '5235640836',
 'fansTotal': '粉丝110357人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/d0668ac0jw8f2yxen2vydj20yi0yi40c.jpg',
 'name': '重庆imini婚纱馆'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝110357人' for column 'fansTotal' at row 1")
2018-07-24 16:05:34 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/huihuixiaochu',
 'blogger': '5235640836',
 'fansTotal': '粉丝99248人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.180.180.50/59402e97jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '烩烩小厨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝99248人' for column 'fansTotal' at row 1")
2018-07-24 16:05:34 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5355820419',
 'blogger': '5235640836',
 'fansTotal': '粉丝3104人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.749.749.50/005Qstyjly8fisczl2xx1j30ku0kt0u0.jpg',
 'name': '她就是佳琪'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3104人' for column 'fansTotal' at row 1")
2018-07-24 16:05:34 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5878675399',
 'blogger': '5235640836',
 'fansTotal': '粉丝54351人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.2.750.750.50/006pQk19jw8f71jsd9qdwj30ku0kzwfo.jpg',
 'name': '菲芝蔓纤体美容-马冬'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝54351人' for column 'fansTotal' at row 1")
2018-07-24 16:05:34 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806449563',
 'blogger': '5235640836',
 'fansTotal': '粉丝926855人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.512.512.50/a747059bly8fpn89pc0slj20e80e8js8.jpg',
 'name': '美图萌萌酱'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝926855人' for column 'fansTotal' at row 1")
2018-07-24 16:05:34 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/whymagic',
 'blogger': '5235640836',
 'fansTotal': '粉丝14642人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.180.180.50/69aee3c9jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '神的共犯何志武'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝14642人' for column 'fansTotal' at row 1")
2018-07-24 16:05:34 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/DZIXY',
 'blogger': '5235640836',
 'fansTotal': '粉丝28781人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.10.492.492.50/e415adbdjw8fczgodeso4j20do0e8q3e.jpg',
 'name': 'DZIXY大嘴小一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝28781人' for column 'fansTotal' at row 1")
2018-07-24 16:05:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2497371971',
 'blogger': '5235640836',
 'fansTotal': '粉丝98人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.290.290.50/94dadf43jw1f016ekbo3aj2082082dg0.jpg',
 'name': '找船的海盗'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝98人' for column 'fansTotal' at row 1")
2018-07-24 16:05:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5651086426',
 'blogger': '5235640836',
 'fansTotal': '粉丝14811人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.996.996.50/006arnJgly8fk78i3xc81j30ro0ro758.jpg',
 'name': '超大番石榴'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝14811人' for column 'fansTotal' at row 1")
2018-07-24 16:05:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5851065502',
 'blogger': '5235640836',
 'fansTotal': '粉丝54914人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.10.0.730.730.50/006nYtqely8fglnojg970j30ku0kawfo.jpg',
 'name': '僮颜美容咨询师之之'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝54914人' for column 'fansTotal' at row 1")
2018-07-24 16:05:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/tunable',
 'blogger': '5235640836',
 'fansTotal': '粉丝18460人',
 'headshot': 'http://tva2.sinaimg.cn/crop.588.529.520.520.50/a81f0e7bjw8fcnmm53zhij216o16oayf.jpg',
 'name': 'tunable-jojo美国代购'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝18460人' for column 'fansTotal' at row 1")
2018-07-24 16:05:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2806479950',
 'blogger': '5235640836',
 'fansTotal': '粉丝3794人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1125.1125.50/a7477c4ely8ft7bfrv5gsj20v90v940u.jpg',
 'name': 'AngelicJ71好甜'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3794人' for column 'fansTotal' at row 1")
2018-07-24 16:05:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/chbcnet',
 'blogger': '5235640836',
 'fansTotal': '粉丝107183人',
 'headshot': 'http://tva1.sinaimg.cn/crop.6.6.173.173.50/5fb3dbb1gw1eop2ktrznyj2050050aab.jpg',
 'name': '华广网--中国华艺广播公司'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝107183人' for column 'fansTotal' at row 1")
2018-07-24 16:05:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2940229071',
 'blogger': '5235640836',
 'fansTotal': '粉丝132人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.720.720.50/af4055cfjw8ene1fmpkrtj20k00k0gmp.jpg',
 'name': '思无邪1949'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝132人' for column 'fansTotal' at row 1")
2018-07-24 16:05:37 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/benefit',
 'blogger': '5235640836',
 'fansTotal': '粉丝694483人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.180.180.50/69427b8bjw8f12750o8t2j2050050dfq.jpg',
 'name': 'benefit贝玲妃的微博'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝694483人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3244159200',
 'blogger': '5235640836',
 'fansTotal': '粉丝23669人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.1242.1242.50/c15df0e0jw8f6v451kq1ej20yi0yijum.jpg',
 'name': 'A_夏雨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝23669人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5782475631',
 'blogger': '5235640836',
 'fansTotal': '粉丝2197人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.996.996.50/006jkG3Zly8frmab27aamj30ro0rodhq.jpg',
 'name': '就是Duan阿duan'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝2197人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3691964202',
 'blogger': '5235640836',
 'fansTotal': '粉丝20005人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.750.750.50/dc0ee72aly8fia1m8r4otj20ku0kut9w.jpg',
 'name': '我是歪牙'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝20005人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2402983764',
 'blogger': '5235640836',
 'fansTotal': '粉丝2645人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.17.111.684.684.50/8f3a9f54ly8fgm9vk7pkqj20m80m8n7k.jpg',
 'name': '盈丰专业灯牌订制厂家'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝2645人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5043828015',
 'blogger': '5235640836',
 'fansTotal': '粉丝632人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.512.512.50/005vlo4Lly8fm1dvwekqlj30e80e8q43.jpg',
 'name': 'APing98'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝632人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/ping136690482',
 'blogger': '5235640836',
 'fansTotal': '粉丝10028人',
 'headshot': 'http://tva3.sinaimg.cn/crop.37.21.384.384.50/006aXirIjw1f1rs00kwswj30di0ht0v5.jpg',
 'name': '泽莹老师'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝10028人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5237190151',
 'blogger': '5235640836',
 'fansTotal': '粉丝2581人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.0.750.750.50/005IqIoTly8fsxjimjvbuj30ku0kut9b.jpg',
 'name': 'Mr蜡笔先生'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝2581人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/perfectidphoto',
 'blogger': '5235640836',
 'fansTotal': '粉丝3043人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.0.750.750.50/0061uBzNjw8f3hhjkl5xzj30ku0ku0t2.jpg',
 'name': '完美证照'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3043人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3205374414',
 'blogger': '5235640836',
 'fansTotal': '粉丝1293人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.996.996.50/bf0e21cejw8f6hvwzf5mtj20ro0rpgow.jpg',
 'name': 'AJun姜姜'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝1293人' for column 'fansTotal' at row 1")
2018-07-24 16:05:42 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/1308391574',
 'blogger': '5235640836',
 'fansTotal': '粉丝1296194人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.1125.1125.50/4dfc7896ly8ft6rkkonyvj20v90v975s.jpg',
 'name': '高瀚宇KD'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝1296194人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5884259049',
 'blogger': '5235640836',
 'fansTotal': '粉丝1032人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.512.512.50/006qdKA1jw8f1z1juw0nbj30e80e8mxk.jpg',
 'name': '星妈0130'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝1032人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5244040548',
 'blogger': '5235640836',
 'fansTotal': '粉丝12073人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1242.1242.50/005ITsvajw8f3w7r0duzpj30yi0yjjz3.jpg',
 'name': 'lonely碗'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝12073人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/samlee221',
 'blogger': '5235640836',
 'fansTotal': '粉丝1085989人',
 'headshot': 'http://tva2.sinaimg.cn/crop.2.0.797.797.50/68e4dd93jw8eytk5cto8gj20m80m810c.jpg',
 'name': '歌手李圣杰'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝1085989人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5073632657',
 'blogger': '5235640836',
 'fansTotal': '粉丝212853人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.0.996.996.50/005xmrCNjw8f0kauzkioej30ro0rodgq.jpg',
 'name': '万年奔波儿灞'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝212853人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/chinaphilipstvc219',
 'blogger': '5235640836',
 'fansTotal': '粉丝887969人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.69.74.428.428.50/9f6cd689ly8fh94gr96nzj20fr0frn1c.jpg',
 'name': '飞利浦电视'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝887969人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2961021294',
 'blogger': '5235640836',
 'fansTotal': '粉丝1866人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.1125.1125.50/b07d996ely8fpfdkyu0tkj20v90v9wgz.jpg',
 'name': '野生的象'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝1866人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5780565993',
 'blogger': '5235640836',
 'fansTotal': '粉丝11338人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.0.1556.1556.50/006jcFhnjw1f4ldqf7slfj31781780yh.jpg',
 'name': '鹰视社'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝11338人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/3163880702',
 'blogger': '5235640836',
 'fansTotal': '粉丝3166人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.9.493.493.50/bc94fcfely8flauyepa6nj20dp0e8t92.jpg',
 'name': '算卦半仙我姓杨'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3166人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/5794206727',
 'blogger': '5235640836',
 'fansTotal': '粉丝3594人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.499.499.50/006k7TRdgw1ez20ynvhlrj30dw0dw74z.jpg',
 'name': '克丝可清个人洗护品牌'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝3594人' for column 'fansTotal' at row 1")
2018-07-24 16:05:47 [scrapy.core.scraper] ERROR: Error processing {'attentionLink': 'https://weibo.cn/u/2994078362',
 'blogger': '5235640836',
 'fansTotal': '粉丝2266人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.996.996.50/b276029ajw8fczojzfs4uj20ro0rpq53.jpg',
 'name': '清霜溯雪'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 13, in process_item
    db.otherOprate(sql, params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect integer value: '粉丝2266人' for column 'fansTotal' at row 1")
2018-07-24 16:10:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:10:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:10:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:10:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:10:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:10:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:10:54 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:10:54 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:10:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:10:54 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:10:54 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:11:09 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/profile?filter=1&page=2> (referer: https://weibo.cn/5235640836/profile?filter=1&page=1)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 131, in parseWeiBo
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:11:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:12:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:12:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:12:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:12:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:12:03 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:12:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:12:04 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:12:04 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:12:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:12:04 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:12:04 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:12:17 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:12:17 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:12:17 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:12:17 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:12:18 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:12:18 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:12:18 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:12:18 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:12:18 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:12:18 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:12:18 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:12:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/profile?filter=1&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 131, in parseWeiBo
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:12:30 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:12:30 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 16:12:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3043,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 18839,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 8, 12, 30, 935126),
 'item_scraped_count': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'request_depth_max': 3,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'spider_exceptions/IndexError': 2,
 'start_time': datetime.datetime(2018, 7, 24, 8, 12, 18, 420410)}
2018-07-24 16:12:30 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 16:12:38 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:12:38 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:12:38 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:12:38 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:12:38 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:12:38 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:12:39 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:12:39 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:12:39 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:12:39 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:12:39 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:12:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/profile?filter=1&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 131, in parseWeiBo
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:12:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:12:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 16:12:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 3043,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 18839,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 8, 12, 50, 861265),
 'item_scraped_count': 31,
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'request_depth_max': 3,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'spider_exceptions/IndexError': 2,
 'start_time': datetime.datetime(2018, 7, 24, 8, 12, 39, 139595)}
2018-07-24 16:12:50 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 16:12:57 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:12:57 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:12:57 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:12:57 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:12:58 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:12:58 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:12:58 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:12:58 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:12:58 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:12:58 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:12:58 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:13:11 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:13:11 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:13:11 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:13:11 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:13:12 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:13:12 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:13:12 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:13:12 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:13:12 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:13:12 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:13:12 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:13:37 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:13:37 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:13:37 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:13:37 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:13:37 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:13:37 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:13:38 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:13:38 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:13:38 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:13:38 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:13:38 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:13:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/profile?filter=1&page=2> (referer: https://weibo.cn/5235640836/profile?filter=1&page=1)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 131, in parseWeiBo
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:14:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:14:38 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 26 pages/min), scraped 217 items (at 217 items/min)
2018-07-24 16:14:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/follow?page=20> (referer: https://weibo.cn/5235640836/follow?page=19)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:14:40 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 16:14:40 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 14253,
 'downloader/request_count': 27,
 'downloader/request_method_count/GET': 27,
 'downloader/response_bytes': 97818,
 'downloader/response_count': 27,
 'downloader/response_status_count/200': 27,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 8, 14, 40, 900559),
 'item_scraped_count': 227,
 'log_count/ERROR': 3,
 'log_count/INFO': 10,
 'request_depth_max': 19,
 'response_received_count': 27,
 'scheduler/dequeued': 27,
 'scheduler/dequeued/memory': 27,
 'scheduler/enqueued': 27,
 'scheduler/enqueued/memory': 27,
 'spider_exceptions/IndexError': 3,
 'start_time': datetime.datetime(2018, 7, 24, 8, 13, 38, 262977)}
2018-07-24 16:14:40 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 16:16:42 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:16:42 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:16:42 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:16:42 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:16:43 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:16:43 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:16:43 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:16:43 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:16:43 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:16:43 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:16:43 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:18:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:18:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:18:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:18:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:18:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:18:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:18:01 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:18:01 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:18:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:18:01 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:18:01 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:23:53 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:23:53 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:23:53 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:23:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:23:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:23:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:23:53 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline',
 'sina.pipelines.SinaFansPipeline',
 'sina.pipelines.SinaGroupPipeline',
 'sina.pipelines.SinaWeiBoPipeline']
2018-07-24 16:23:53 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:23:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:23:53 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:23:53 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:27:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:27:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:27:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:27:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:27:01 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:27:01 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:27:01 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-24 16:27:01 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:27:01 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:27:01 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:27:01 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-13 10:50:07&nbsp;来自手机微博触屏版',
 'commentNumber': '评论[0]',
 'content': '【心理箴言】现实是污浊的河流，要想接受污浊的河流而自身不被污染，我们必须成为大海。 \u200b\u200b\u200b',
 'goodNumber': '赞[9]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-12 13:41:45&nbsp;来自微博 weibo.com',
 'commentNumber': '评论[0]',
 'content': '【趣味测试】下图中第一眼看到的三个词就是对你的描述哟~应该蛮准的。 \u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-11 22:22:36&nbsp;来自微博 weibo.com',
 'commentNumber': '评论[0]',
 'content': '一个成熟的人，应该多点宽容与理解。对于过去不理解的，以后会理解，小时候不理解的，长大了会理解，长大了不理解的，年老了会理解。无论如何也理解不了的呢？只要人家没违法，我们就要理解其存在的合理性并容许别人以其喜欢的方式自由存在。理解别人，就是理解自己。 '
            '\u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-11 08:52:38&nbsp;来自手机微博触屏版',
 'commentNumber': '评论[0]',
 'content': '做你自己喜欢的事，哪怕别人都笑你傻，你也完全可以全身心地去做，只要你喜欢，只要做这件事会让你快乐！只有你的快乐才是你该在乎的；别怕别人说什么，除了帮你快乐的话，你都可以不听。这样你的心就简单了，事就简单了，你的快乐就多了。[哈哈] '
            '\u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-10 13:31:24&nbsp;来自手机微博触屏版',
 'commentNumber': '评论[0]',
 'content': '我是要为人民服务，但不可能为所有的人、所有的民服务；我要为我的亲人、友人、熟人、美人这样的“民”服务，光这些就够我忙活的了，哪还有精力再为其它的人其它的民服务呢？ '
            '\u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-09 23:16:05&nbsp;来自微博 weibo.com',
 'commentNumber': '评论[0]',
 'content': '人生的路走走停停是一种闲适，边走边看是一种优雅，边走边忘是一种豁达。人生艰难，但是如果你有笑对人生的能力，你就有享受人生的能力。我们曾如此渴望命运的波澜，到最后才发现：人生最曼妙的风景，竟是内心的淡定与从容。我们曾如此期盼外界的认可，到最后才知道：世界是自己的，与他人毫无关系 '
            '\u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-09 10:10:24&nbsp;来自手机微博触屏版',
 'commentNumber': '评论[0]',
 'content': '总有被误解的时候，淡淡一笑；总有委屈的时候，坦然一笑，心大了，乐多了；心小了，愁多了，生活中不能事事顺心，人生中不会处处如意，或许有些烦恼是别人给的，有些愁绪是自己找的，不管怎样来的，不论如何得的，看淡了，坦然了，给心一个安乐，给情一个安宁，生活，多了开心，人生，就多了乐趣。 '
            '\u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-08 14:39:56&nbsp;来自手机微博触屏版',
 'commentNumber': '转发[0]',
 'content': '三伏天了，啥叫三伏？当然是幸福对你贴贴“伏伏”，好运被你轻松降“伏”，吉祥也来乖乖臣“伏”。三伏天，愿你三伏清凉好心情！  '
            '我在这里：  ',
 'goodNumber': '显示地图',
 'transmitNumber': '赞[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-07 23:54:51&nbsp;来自微博 weibo.com',
 'commentNumber': '评论[0]',
 'content': '告别单身，马上就加入到腾讯女性 \u200b\u200b\u200b',
 'goodNumber': '赞[3]',
 'transmitNumber': '转发[1]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:08 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-07 08:51:52&nbsp;来自微博 weibo.com',
 'commentNumber': '评论[0]',
 'content': '世上或许有一段不可替代的感情，却没有一个人是不可替代的。[yz砸] \u200b\u200b\u200b',
 'goodNumber': '赞[3]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-06 12:45:40&nbsp;来自微博 weibo.com',
 'commentNumber': '评论[0]',
 'content': '刚出网吧，就看见她的背影，背着一个可爱的熊猫包包，可惜却不能叫住她——23:30 \u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-03-05 16:26:22&nbsp;来自手机微博触屏版',
 'commentNumber': '评论[0]',
 'content': '【Q版与暗黑共存萌幻页游《龙魂大陆》试玩】也许有的玩家感到诧异，萌系页游不都是清新阳光的吗，啥时候还走起暗黑风啦？没错，今天八云试玩的《龙魂大陆》就是这样的一款独特的页游。究竟该游戏有何特色，赶紧和八云去游戏内体验一番便知。[cc疑问] '
            '\u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2016-01-06 16:55:13&nbsp;来自手机微博触屏版',
 'commentNumber': '转发[0]',
 'content': '我最害怕的是你们混得比我好，那样我会不安，可是我更担心你们过得不好。[萌萌捶地笑]  我在这里：  ',
 'goodNumber': '显示地图',
 'transmitNumber': '赞[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-26 11:55:45&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-25 22:18:33&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-25 22:16:17&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-25 22:12:23&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-18 13:49:15&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-17 14:30:19&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:10 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-15 12:09:54&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-15 07:34:54&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-15 07:30:56&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-14 21:32:26&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-14 21:25:48&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-14 21:23:07&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-12 16:05:25&nbsp;来自秦时明月手游',
 'commentNumber': '评论[1]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-12 15:58:56&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-12 15:45:02&nbsp;来自秦时明月手游',
 'commentNumber': '评论[1]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-11 12:13:06&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-10 19:51:27&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-10 11:52:18&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-09 12:14:32&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-09 11:58:53&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-09 11:50:39&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-08 16:56:23&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-02-08 16:49:55&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-19 03:23:01&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-19 03:11:00&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-19 03:08:12&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-18 08:19:00&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-18 04:59:20&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-18 04:45:04&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-17 13:24:24&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-17 13:22:25&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-17 04:43:00&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-16 02:54:44&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-16 02:53:02&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-16 02:51:27&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-15 09:20:27&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-15 05:02:53&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-15 04:58:13&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-14 04:47:08&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-14 04:37:26&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-14 04:35:32&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-13 08:42:26&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-13 08:41:24&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-13 08:37:10&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-12 02:21:25&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-12 02:10:41&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:27:19 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2015-01-12 02:09:33&nbsp;来自秦时明月手游',
 'commentNumber': '评论[0]',
 'content': '《秦时明月》破秦兵百万，做秦时霸王！ ',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 49, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1054, "Unknown column 'content' in 'field list'")
2018-07-24 16:36:04 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:36:04 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:36:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:36:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:36:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:36:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:36:05 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-24 16:36:05 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:36:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:36:05 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:36:05 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:36:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'fansTotal': '粉丝156人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.290.290.50/ec6a21d5jw8eck6kgnmbij2082082jre.jpg',
 'name': '水月bc0qukdt3</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝248人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3966378453&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5204249302"><img '
         'src="http://tva3.sinaimg.cn/crop.0.0.150.150.50/005GcuYSjw1ejecaga4enj3046046q2w.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5204249302">新亭紅魔一一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:36:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:37:58 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:37:58 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:37:58 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:37:59 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:39:21 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:39:21 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:39:21 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-24 16:39:21 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:39:21 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:39:21 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:39:21 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:39:49 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'fansTotal': '粉丝156人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.290.290.50/ec6a21d5jw8eck6kgnmbij2082082jre.jpg',
 'name': '水月bc0qukdt3</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝248人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3966378453&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5204249302"><img '
         'src="http://tva3.sinaimg.cn/crop.0.0.150.150.50/005GcuYSjw1ejecaga4enj3046046q2w.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5204249302">新亭紅魔一一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:39:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:40:21 [scrapy.extensions.logstats] INFO: Crawled 26 pages (at 26 pages/min), scraped 234 items (at 234 items/min)
2018-07-24 16:41:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/follow?page=20> (referer: https://weibo.cn/5235640836/follow?page=19)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:41:09 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-11-22 16:21:06&nbsp;来自陌陌',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': 'http://t.cn/R7EiPUE',
 'transmitNumber': '<img '
                   'src="http://ww3.sinaimg.cn/wap180/005IkdlWjw1emjumeh50oj30e70gv78l.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:41:09 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-11-13 09:15:55&nbsp;来自陌陌',
 'commentNumber': '原图',
 'content': '我在陌陌，陌陌号：89240017，愿得一人心，白首不相离。。',
 'goodNumber': 'http://t.cn/R7eOeqQ',
 'transmitNumber': '<img '
                   'src="http://ww2.sinaimg.cn/wap180/005IkdlWjw1em93r88n42j30go0miq4q.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:41:09 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-09-05 11:50:50&nbsp;来自新浪微博4G版',
 'commentNumber': '原图',
 'content': '这狗狗乖不 ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://ww1.sinaimg.cn/wap180/005IkdlWjw1ek1gbda3edj30xc18g448.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:41:09 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-08-28 17:30:02&nbsp;来自新浪微博4G版',
 'commentNumber': '原图',
 'content': '分享图片 ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://ww4.sinaimg.cn/wap180/005IkdlWjw1ejshbleyj1j30hs0dcdgu.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:41:09 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-08-15 15:47:09&nbsp;来自新浪微博4G版',
 'commentNumber': '原图',
 'content': '分享图片 ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://ww1.sinaimg.cn/wap180/005IkdlWjw1ejddahv3nsj30hs0npq46.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:41:09 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-08-14 08:42:00&nbsp;来自新浪微博4G版',
 'commentNumber': '原图',
 'content': '这样的基友就该拖出去宰了 ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://ww1.sinaimg.cn/wap180/005IkdlWjw1ejbvdjekdqj318g0xcn2c.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:41:09 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-08-13 15:16:40&nbsp;来自分享按钮',
 'commentNumber': '<img '
                  'src="http://ww4.sinaimg.cn/wap180/005IkdlWjw1ejb16841avj30f50bdq6x.jpg" '
                  'alt="图片" class="ib" />',
 'content': '【女子公园放生毒蛇引争议 网友斥其“放生无下限”】下载查看：',
 'goodNumber': '@百度新闻',
 'transmitNumber': '女子公园放生毒蛇引争议 网友斥其“放生无下限”'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:41:09 [scrapy.core.engine] INFO: Closing spider (finished)
2018-07-24 16:41:09 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 24821,
 'downloader/request_count': 46,
 'downloader/request_method_count/GET': 46,
 'downloader/response_bytes': 177325,
 'downloader/response_count': 46,
 'downloader/response_status_count/200': 46,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 7, 24, 8, 41, 9, 270409),
 'item_scraped_count': 419,
 'log_count/ERROR': 10,
 'log_count/INFO': 10,
 'request_depth_max': 21,
 'response_received_count': 46,
 'scheduler/dequeued': 46,
 'scheduler/dequeued/memory': 46,
 'scheduler/enqueued': 46,
 'scheduler/enqueued/memory': 46,
 'spider_exceptions/IndexError': 2,
 'start_time': datetime.datetime(2018, 7, 24, 8, 39, 21, 954271)}
2018-07-24 16:41:09 [scrapy.core.engine] INFO: Spider closed (finished)
2018-07-24 16:41:54 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:41:54 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:41:54 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:41:54 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:42:54 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:42:54 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:42:54 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-24 16:42:54 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:42:54 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:42:54 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:42:54 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:43:45 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'fansTotal': '粉丝156人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.290.290.50/ec6a21d5jw8eck6kgnmbij2082082jre.jpg',
 'name': '水月bc0qukdt3</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝248人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3966378453&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5204249302"><img '
         'src="http://tva3.sinaimg.cn/crop.0.0.150.150.50/005GcuYSjw1ejecaga4enj3046046q2w.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5204249302">新亭紅魔一一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:43:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:43:54 [scrapy.extensions.logstats] INFO: Crawled 23 pages (at 23 pages/min), scraped 204 items (at 204 items/min)
2018-07-24 16:45:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:45:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:45:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:45:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:46:04 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:46:04 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:46:04 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-24 16:46:04 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:46:04 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:46:04 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:46:04 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:46:16 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝56人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.180.180.50/6b2564e9jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': 'Spand-a</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝810人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1797612777&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5541458613"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.0.667.667.50/00631owJly8fthqzjbs19j30ij0ijt9p.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5541458613">felixorange-'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月09日 08:33&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '赞[5]',
 'content': '【骑士三方交易评级：胡德希尔能帮骑士争冠吗】',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/006c9ccRgy1fo9w73o9kdj30c8062dge.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月09日 08:16&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[0]',
 'content': '骑士。。',
 'goodNumber': '赞[7]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月07日 10:41&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[6]',
 'content': '我发起了一个投票 【你最喜欢的国内篮球解说是？】',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/006c9ccRgy1fo7ooumkmpj30fa08cjt1.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月06日 16:45&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[3]',
 'content': '有点萌。 \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/006c9ccRgy1fo6tkrvjwuj30dg0dm0tg.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月06日 12:28&nbsp;来自微博 weibo.com',
 'commentNumber': '原图',
 'content': '爵士今天客场133-109大胜鹈鹕，据统计自戈贝尔复出后，爵士百回合净胜10.9分(全联盟第一），投篮命中率50.5%(全联盟第二），取得7胜2负的战绩(全联盟第二）。',
 'goodNumber': '全文',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/006c9ccRgy1fo6m53a5msj30sg0g0dgg.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月06日 12:18&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[4]',
 'content': '洛佩斯这是？ \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/006c9ccRgy1fo6lurdvqug308c08dhdt.gif" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月06日 11:53&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[7]',
 'content': '勇士询价布拉德利？ \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/006c9ccRgy1fo6l50468kj30j90clqeb.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月05日 16:56&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[4]',
 'content': '泡椒你这是？ \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/006c9ccRgy1fo5oa3phakj30fn0fiabf.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月05日 13:56&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[12]',
 'content': '老鹰球迷唐斯。[哈哈]',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/006c9ccRgy1fo5j2m9ip7j30m80bowga.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月05日 12:36&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[2]',
 'content': '这要是走步。。 \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/006c9ccRgy1fo5gromgu5g307z05j4qq.gif" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '04月06日 19:45&nbsp;来自小米6 拍人更美',
 'commentNumber': '原图',
 'content': '唯有美食与美女不可辜负！ \u200b\u200b\u200b',
 'goodNumber': '组图共9张',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/006pnSFFgy1fq36bs6s0jj30zn0qowm8.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:46:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '04月03日 21:35&nbsp;来自小米6 拍人更美',
 'commentNumber': '原图',
 'content': '每晚都需要抱着去看看外面的灯红酒绿。 \u200b\u200b\u200b',
 'goodNumber': '组图共9张',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/006pnSFFgy1fpzsn3r2vaj30qo1ben2y.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:46:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '03月26日 00:02&nbsp;来自小米6 拍人更美',
 'commentNumber': '原图',
 'content': '小情人[太开心][太开心] \u200b\u200b\u200b',
 'goodNumber': '组图共5张',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/006pnSFFgy1fppiamqmknj31400qoq6q.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:46:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '02月20日 20:17&nbsp;来自粉丝红包',
 'commentNumber': '赞[0]',
 'content': '',
 'goodNumber': '@陈欧',
 'transmitNumber': '努力努力再努力x 的红包'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:46:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '01月06日 23:13&nbsp;来自手机酷狗安卓版',
 'commentNumber': '原图',
 'content': '我正在听刘德华的歌曲《谢谢你的爱 (国语)》（来自',
 'goodNumber': 'http://t.cn/RHrrFMu',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/006pnSFFgy1fn7aleratcj30dc0dc755.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '今天 08:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[123]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftjyfervcej20f00qoqgm.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月23日 22:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[127]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftgdhdymnyj20m80hstmj.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月23日 21:30&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[65]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftg5fibuspj21kw1kwe81.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月23日 18:29&nbsp;来自专业版微博',
 'commentNumber': '原图',
 'content': '枯燥的知识千篇一律，有趣的内容万里挑一！',
 'goodNumber': '组图共6张',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftjz106c93j20m80vuajr.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月23日 08:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[226]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/7f840a09gy1ftge23xnhaj20f00qowwn.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月22日 21:30&nbsp;来自微博 weibo.com',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': '组图共2张',
 'transmitNumber': '<img '
                   'src="http://wx4.sinaimg.cn/wap180/7f840a09gy1ftf9244h1yj20yi0yi0wq.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月22日 12:16&nbsp;来自超话',
 'commentNumber': '<img '
                  'src="http://wx4.sinaimg.cn/wap180/7f840a09gy1ftiinard81j20rs1dh7sh.jpg" '
                  'alt="图片" class="ib" />',
 'content': '',
 'goodNumber': '#双世宠妃#',
 'transmitNumber': '@邢昭林'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'commentNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月22日 08:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[198]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/7f840a09gy1ftbthui9g8j20f00qo76t.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月21日 22:00&nbsp;来自微博 weibo.com',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': '#剧版镇魂#',
 'transmitNumber': '<img '
                   'src="http://wx4.sinaimg.cn/wap180/7f840a09gy1ftg9oc8z6oj20m80hsq66.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:46:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月21日 08:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[295]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftbtfo8c4kj20f00qo0v4.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:47:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '06月15日 06:30&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[0]',
 'content': '路很直，但找不到方向 \u200b\u200b\u200b',
 'goodNumber': '赞[2]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:47:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '05月28日 14:09&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '原图',
 'content': '来过吧[允悲] ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/0065BJAUly1frr0v7uiqyj33402c0b2b.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:47:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '05月25日 13:24&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[2]',
 'content': '睡个午觉，做梦做的一塌浮图 \u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:47:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '04月16日 21:01&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[0]',
 'content': '操他妈的生活 \u200b\u200b\u200b',
 'goodNumber': '赞[2]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:47:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '03月06日 22:08&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[1]',
 'content': '当一个男人放下面子去挣钱的时候证明他真的长大了 ',
 'goodNumber': '赞[1]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:47:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '02月22日 23:35&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '转发[0]',
 'content': '想想怎么突然就2018年了 ',
 'goodNumber': '显示地图',
 'transmitNumber': '赞[1]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:47:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '02月15日 22:36&nbsp;来自红包活动',
 'commentNumber': '赞[0]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/67615c84ly1fnds9ik4vvj20kk0fcwgo.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:47:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '02月15日 22:36&nbsp;来自红包活动',
 'commentNumber': '赞[0]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/67615c84ly1fnds9ik4vvj20kk0fcwgo.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:47:04 [scrapy.extensions.logstats] INFO: Crawled 24 pages (at 24 pages/min), scraped 162 items (at 162 items/min)
2018-07-24 16:47:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/2517436943/profile?filter=1&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 132, in parseWeiBo
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:53:00 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:53:00 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:53:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:53:00 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:54:39 [twisted] CRITICAL: Unhandled error in Deferred:
2018-07-24 16:54:39 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 1386, in _inlineCallbacks
    result = g.send(result)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\engine.py", line 69, in __init__
    self.downloader = downloader_cls(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\core\downloader\__init__.py", line 88, in __init__
    self.middleware = DownloaderMiddlewareManager.from_crawler(crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\misc.py", line 44, in load_object
    mod = import_module(module)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\importlib\__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 994, in _gcd_import
  File "<frozen importlib._bootstrap>", line 971, in _find_and_load
  File "<frozen importlib._bootstrap>", line 955, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 665, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 678, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 10, in <module>
    from sina.util.cookies import cookies
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 158, in <module>
    cookie = processCookies(i['user'], i['pwd'])
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\cookies.py", line 144, in processCookies
    name = browser.find_element_by_id('loginName')
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 351, in find_element_by_id
    return self.find_element(by=By.ID, value=id_)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 955, in find_element
    'value': value})['value']
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\selenium\webdriver\remote\webdriver.py", line 312, in execute
    self.error_handler.check_response(response)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\selenium\webdriver\remote\errorhandler.py", line 242, in check_response
    raise exception_class(message, screen, stacktrace)
selenium.common.exceptions.NoSuchElementException: Message: no such element: Unable to locate element: {"method":"id","selector":"loginName"}
  (Session info: chrome=68.0.3423.2)
  (Driver info: chromedriver=2.40.565498 (ea082db3280dd6843ebfb08a625e3eb905c4f5ab),platform=Windows NT 6.1.7601 SP1 x86)

2018-07-24 16:54:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-24 16:54:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-24 16:54:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-24 16:54:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-24 16:56:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'sina.middlewares.SinaUseAgentChange',
 'sina.middlewares.SinaCookieChange',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'sina.middlewares.SinaDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-07-24 16:56:02 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'sina.middlewares.SinaSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-07-24 16:56:02 [scrapy.middleware] INFO: Enabled item pipelines:
['sina.pipelines.SinaPipeline']
2018-07-24 16:56:02 [scrapy.core.engine] INFO: Spider opened
2018-07-24 16:56:02 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-07-24 16:56:02 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:56:02 [sina_spider] INFO: Spider opened: sina_spider
2018-07-24 16:56:16 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝56人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.180.180.50/6b2564e9jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': 'Spand-a</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝810人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1797612777&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5541458613"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.0.667.667.50/00631owJly8fthqzjbs19j30ij0ijt9p.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5541458613">felixorange-'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月09日 08:33&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '赞[5]',
 'content': '【骑士三方交易评级：胡德希尔能帮骑士争冠吗】',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/006c9ccRgy1fo9w73o9kdj30c8062dge.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月09日 08:16&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[0]',
 'content': '骑士。。',
 'goodNumber': '赞[7]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月07日 10:41&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[6]',
 'content': '我发起了一个投票 【你最喜欢的国内篮球解说是？】',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/006c9ccRgy1fo7ooumkmpj30fa08cjt1.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月06日 16:45&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[3]',
 'content': '有点萌。 \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/006c9ccRgy1fo6tkrvjwuj30dg0dm0tg.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月06日 12:28&nbsp;来自微博 weibo.com',
 'commentNumber': '原图',
 'content': '爵士今天客场133-109大胜鹈鹕，据统计自戈贝尔复出后，爵士百回合净胜10.9分(全联盟第一），投篮命中率50.5%(全联盟第二），取得7胜2负的战绩(全联盟第二）。',
 'goodNumber': '全文',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/006c9ccRgy1fo6m53a5msj30sg0g0dgg.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月06日 12:18&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[4]',
 'content': '洛佩斯这是？ \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/006c9ccRgy1fo6lurdvqug308c08dhdt.gif" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月06日 11:53&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[7]',
 'content': '勇士询价布拉德利？ \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/006c9ccRgy1fo6l50468kj30j90clqeb.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月05日 16:56&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[4]',
 'content': '泡椒你这是？ \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/006c9ccRgy1fo5oa3phakj30fn0fiabf.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月05日 13:56&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[12]',
 'content': '老鹰球迷唐斯。[哈哈]',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/006c9ccRgy1fo5j2m9ip7j30m80bowga.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'comeFrom': '02月05日 12:36&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[2]',
 'content': '这要是走步。。 \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/006c9ccRgy1fo5gromgu5g307z05j4qq.gif" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '04月06日 19:45&nbsp;来自小米6 拍人更美',
 'commentNumber': '原图',
 'content': '唯有美食与美女不可辜负！ \u200b\u200b\u200b',
 'goodNumber': '组图共9张',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/006pnSFFgy1fq36bs6s0jj30zn0qowm8.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:56:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '04月03日 21:35&nbsp;来自小米6 拍人更美',
 'commentNumber': '原图',
 'content': '每晚都需要抱着去看看外面的灯红酒绿。 \u200b\u200b\u200b',
 'goodNumber': '组图共9张',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/006pnSFFgy1fpzsn3r2vaj30qo1ben2y.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:56:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '03月26日 00:02&nbsp;来自小米6 拍人更美',
 'commentNumber': '原图',
 'content': '小情人[太开心][太开心] \u200b\u200b\u200b',
 'goodNumber': '组图共5张',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/006pnSFFgy1fppiamqmknj31400qoq6q.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:56:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '02月20日 20:17&nbsp;来自粉丝红包',
 'commentNumber': '赞[0]',
 'content': '',
 'goodNumber': '@陈欧',
 'transmitNumber': '努力努力再努力x 的红包'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:56:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5871897095',
 'comeFrom': '01月06日 23:13&nbsp;来自手机酷狗安卓版',
 'commentNumber': '原图',
 'content': '我正在听刘德华的歌曲《谢谢你的爱 (国语)》（来自',
 'goodNumber': 'http://t.cn/RHrrFMu',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/006pnSFFgy1fn7aleratcj30dc0dc755.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '今天 08:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[123]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftjyfervcej20f00qoqgm.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月23日 22:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[127]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftgdhdymnyj20m80hstmj.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月23日 21:30&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[65]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftg5fibuspj21kw1kwe81.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月23日 18:29&nbsp;来自专业版微博',
 'commentNumber': '原图',
 'content': '枯燥的知识千篇一律，有趣的内容万里挑一！',
 'goodNumber': '组图共6张',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftjz106c93j20m80vuajr.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月23日 08:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[226]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/7f840a09gy1ftge23xnhaj20f00qowwn.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月22日 21:30&nbsp;来自微博 weibo.com',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': '组图共2张',
 'transmitNumber': '<img '
                   'src="http://wx4.sinaimg.cn/wap180/7f840a09gy1ftf9244h1yj20yi0yi0wq.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月22日 12:16&nbsp;来自超话',
 'commentNumber': '<img '
                  'src="http://wx4.sinaimg.cn/wap180/7f840a09gy1ftiinard81j20rs1dh7sh.jpg" '
                  'alt="图片" class="ib" />',
 'content': '',
 'goodNumber': '#双世宠妃#',
 'transmitNumber': '@邢昭林'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'commentNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月22日 08:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[198]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/7f840a09gy1ftbthui9g8j20f00qo76t.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月21日 22:00&nbsp;来自微博 weibo.com',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': '#剧版镇魂#',
 'transmitNumber': '<img '
                   'src="http://wx4.sinaimg.cn/wap180/7f840a09gy1ftg9oc8z6oj20m80hsq66.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:56:41 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'comeFrom': '07月21日 08:00&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[295]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/7f840a09gy1ftbtfo8c4kj20f00qo0v4.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:57:01 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '06月15日 06:30&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[0]',
 'content': '路很直，但找不到方向 \u200b\u200b\u200b',
 'goodNumber': '赞[2]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:57:01 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '05月28日 14:09&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '原图',
 'content': '来过吧[允悲] ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/0065BJAUly1frr0v7uiqyj33402c0b2b.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:57:01 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '05月25日 13:24&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[2]',
 'content': '睡个午觉，做梦做的一塌浮图 \u200b\u200b\u200b',
 'goodNumber': '赞[0]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:57:01 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '04月16日 21:01&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[0]',
 'content': '操他妈的生活 \u200b\u200b\u200b',
 'goodNumber': '赞[2]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:57:01 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '03月06日 22:08&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '评论[1]',
 'content': '当一个男人放下面子去挣钱的时候证明他真的长大了 ',
 'goodNumber': '赞[1]',
 'transmitNumber': '转发[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:57:01 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '02月22日 23:35&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '转发[0]',
 'content': '想想怎么突然就2018年了 ',
 'goodNumber': '显示地图',
 'transmitNumber': '赞[1]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 16:57:01 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '02月15日 22:36&nbsp;来自红包活动',
 'commentNumber': '赞[0]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/67615c84ly1fnds9ik4vvj20kk0fcwgo.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:57:01 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5579672076',
 'comeFrom': '02月15日 22:36&nbsp;来自红包活动',
 'commentNumber': '赞[0]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/67615c84ly1fnds9ik4vvj20kk0fcwgo.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:57:02 [scrapy.extensions.logstats] INFO: Crawled 21 pages (at 21 pages/min), scraped 134 items (at 134 items/min)
2018-07-24 16:57:36 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝120人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.480.480.50/e80602b6ly8fte09ah1dhj20dc0dcq7e.jpg',
 'name': '非专业设计人孙立</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝51672人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3892708022&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/saalaas"><img '
         'src="http://tva1.sinaimg.cn/crop.0.0.180.180.50/80f5dd3cjw1e8qgp5bmzyj2050050aa8.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/saalaas">索罗斯斯基'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:57:36 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝21人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.750.750.50/0072WHxnly8fnahw2qy33j30ku0kudgn.jpg',
 'name': '湖人动态</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝113646人<br/><a '
         'href="https://weibo.cn/attention/add?uid=6456472881&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5994668305"><img '
         'src="http://tvax1.sinaimg.cn/crop.0.0.480.480.50/006xH14tly8ft2hyotywtj30dc0dcta4.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5994668305">公交车大大'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:57:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:58:02 [scrapy.extensions.logstats] INFO: Crawled 43 pages (at 22 pages/min), scraped 279 items (at 145 items/min)
2018-07-24 16:58:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/2517436943/profile?filter=1&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 132, in parseWeiBo
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:58:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝1人',
 'headshot': 'http://tva1.sinaimg.cn/crop.36.30.94.94.50/c08a8beejw8f5tpj0apzdj204q04jjrq.jpg',
 'name': 'Doctor灬J</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝201人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3230305262&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6475628522"><img '
         'src="http://tvax3.sinaimg.cn/default/images/default_avatar_female_50.gif" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6475628522">德鲁大叔55555'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:58:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'comeFrom': '9分钟前&nbsp;来自王德发大师iPhone客户端',
 'commentNumber': '原图',
 'content': '[笑cry][笑cry]成都下暴雨又又又停电了，我心里是奔溃的[泪][泪][泪]',
 'goodNumber': '组图共2张',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/006YYYJzgy1ftl1shxj0xj30qo0zkqc0.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:58:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'comeFrom': '07月22日 23:35&nbsp;来自王德发大师iPhone客户端',
 'commentNumber': '赞[139]',
 'content': '[泪][泪][泪]又尼玛停电了，受不鸟啦…我们只能明天见了，各位… \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/006YYYJzgy1ftj29p20bgj30qo0zk7dj.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:58:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'comeFrom': '07月21日 02:32&nbsp;来自王德发大师iPhone客户端',
 'commentNumber': '赞[140]',
 'content': '从明天开始，老苏，19:00-21:00跟微信铁粉群的吃鸡好不好呀，你们不要老说冷宫群，我最爱的其实还是你们呀～每天一个群哦，每人限定一把，这样不乱，都有机会，么么哒[爱你][爱你] '
            '记得上车多说说话哦，不要含羞，不要含蓄，释放你自己～ \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/006YYYJzgy1ftgw3ehfd9j30go08cjrj.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:58:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'comeFrom': '07月18日 02:12&nbsp;来自王德发大师iPhone客户端',
 'commentNumber': '原图',
 'content': '[可怜][可怜]终于赶上了 '
            '战神末班车，但是还要发个微博道歉，因为我的个人疏忽，给路人小姐姐造成了困扰，对不起，真的很对不起，我其实后来要你们微信的目的是想下播后，给你们解释，以后不要了，真的是很对不起你们啊，如果你看到我的微博道歉了，希望原谅老王啊，真的不是故意暴露你们隐私的，对不 '
            '\u200b\u200b\u200b&nbsp;',
 'goodNumber': '组图共2张',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/006YYYJzgy1ftden7lomrj31pc0yib2h.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 16:58:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'comeFrom': '07月10日 16:27&nbsp;来自王德发大师iPhone客户端',
 'commentNumber': '赞[101]',
 'content': '换个风格直播，以后严格要求完成任务，否则就惩罚自己，以正军心！[笑而不语][笑而不语] \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/006YYYJzgy1ft4udrjtybj32c0340kjl.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:58:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'comeFrom': '07月05日 15:04&nbsp;来自王德发大师iPhone客户端',
 'commentNumber': '组图共6张',
 'content': '（更新啦）刺激战场7月5号新版设置截图，大家可以借鉴下～纯两指操作，喜欢老苏的多来直播间看看王德发哟[太开心][太开心]关注我的超话， '
            '还有粉丝群一起开黑哦～',
 'goodNumber': 'http://t.cn/RE1mXTc',
 'transmitNumber': '全文'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:58:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'comeFrom': '07月04日 15:20&nbsp;来自王德发大师iPhone客户端',
 'commentNumber': '赞[116]',
 'content': '你们觉得，这个每日吃鸡任务怎么规划有意思捏？欢迎提供～[笑而不语][笑而不语] \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/006YYYJzgy1fsxutk7cvwj32c03407wi.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 16:58:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'comeFrom': '07月02日 14:59&nbsp;来自王德发大师iPhone客户端',
 'commentNumber': '<img '
                  'src="http://wx4.sinaimg.cn/wap180/006YYYJzgy1fsviwhwf9hj30qo1bf0xl.jpg" '
                  'alt="图片" class="ib" />',
 'content': '',
 'goodNumber': '全文',
 'transmitNumber': '组图共3张'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'commentNumber' at row 1")
2018-07-24 16:59:01 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝11人',
 'headshot': 'http://tva1.sinaimg.cn/crop.120.101.333.333.50/c3183583jw8esb37wn5t9j20go0godfx.jpg',
 'name': '为未来奋斗的如花和熊</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝203人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3273143683&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/3969493721"><img '
         'src="http://tvax1.sinaimg.cn/crop.0.0.512.512.50/ec99aad9ly8ft4hvgof7fj20e80e8wgm.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/3969493721">我是小陈222'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:59:02 [scrapy.extensions.logstats] INFO: Crawled 67 pages (at 24 pages/min), scraped 455 items (at 176 items/min)
2018-07-24 16:59:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'fansTotal': '粉丝156人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.290.290.50/ec6a21d5jw8eck6kgnmbij2082082jre.jpg',
 'name': '水月bc0qukdt3</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝248人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3966378453&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5204249302"><img '
         'src="http://tva3.sinaimg.cn/crop.0.0.150.150.50/005GcuYSjw1ejecaga4enj3046046q2w.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5204249302">新亭紅魔一一'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 16:59:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/fans?page=4> (referer: https://weibo.cn/5235640836/fans?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 16:59:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝2人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.41.0.386.386.50/d471a689ly8fll52ht171j20ck0aq74u.jpg',
 'name': '二哥日记本</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝11804人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3564217993&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6427359381"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.0.996.996.50/0070YxMNly8fpylyy78jpj30ro0roq52.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6427359381">晨光如雨_Alex'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:00:02 [scrapy.extensions.logstats] INFO: Crawled 88 pages (at 21 pages/min), scraped 620 items (at 165 items/min)
2018-07-24 17:00:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/6397910297/follow?page=4> (referer: https://weibo.cn/6397910297/follow?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:00:38 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'fansTotal': '粉丝345人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.0.512.512.50/b7b1a482ly8fp3d21luynj20e80e8jsa.jpg',
 'name': '华佐伊小鱼_MbT</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝328人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3081872514&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6415354363"><img '
         'src="http://tvax1.sinaimg.cn/crop.0.0.1242.1242.50/0070aaJtly8fnon8afatuj30yi0yitae.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6415354363">Yan-炎炎</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝10435人<br/><a '
         'href="https://weibo.cn/attention/add?uid=6415354363&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5491429978"><img '
         'src="http://tva4.sinaimg.cn/crop.0.0.200.200.50/005ZDtNgjw1eqq5dz3y8gj305k05kdg4.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5491429978">傲娇的高洁'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:00:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'comeFrom': '06月18日 23:59&nbsp;来自三星android智能手机',
 'commentNumber': '赞[0]',
 'content': '北京的第一天',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/005QLEH6ly1fsfrxhirsuj30j60irdgr.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:00:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'comeFrom': '06月15日 23:25&nbsp;来自三星android智能手机',
 'commentNumber': '赞[0]',
 'content': '很重要的那个人不是男朋友',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/005QLEH6ly1fsca04juonj31jk1jkwon.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:00:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'comeFrom': '03月03日 18:54&nbsp;来自三星android智能手机',
 'commentNumber': '原图',
 'content': '北京宜家攻略',
 'goodNumber': '组图共9张',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/005QLEH6ly1foztrinujsj30qo0qodhx.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:00:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'comeFrom': '01月17日 11:25&nbsp;来自三星android智能手机',
 'commentNumber': '赞[0]',
 'content': '💞💞爱情不是风平浪静的',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/005QLEH6ly1fnjfwgrztuj30mi0u0aph.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect string value: '\\xF0\\x9F\\x92\\x9E\\xF0\\x9F...' for column 'content' at row 1")
2018-07-24 17:00:58 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'comeFrom': '01月16日 21:40&nbsp;来自三星android智能手机',
 'commentNumber': '赞[1]',
 'content': '💞💞一个人往，一个人来',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/005QLEH6ly1fnis3164nyj30mi0u0wtg.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect string value: '\\xF0\\x9F\\x92\\x9E\\xF0\\x9F...' for column 'content' at row 1")
2018-07-24 17:00:58 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'comeFrom': '01月15日 21:58&nbsp;来自三星android智能手机',
 'commentNumber': '赞[1]',
 'content': '《二》',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/005QLEH6ly1fnhmzffp9kj30mi0u0aq0.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:00:58 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'comeFrom': '01月15日 21:53&nbsp;来自三星android智能手机',
 'commentNumber': '赞[0]',
 'content': '《一》',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/005QLEH6ly1fnhmu4p0gzj30mi0u07j6.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:00:58 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'comeFrom': '01月15日 21:48&nbsp;来自三星android智能手机',
 'commentNumber': '赞[0]',
 'content': 'start✍✍✍ \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/005QLEH6ly1fnhmprlb6wj30qo1bejvw.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:00:58 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'comeFrom': '2017-10-10 11:00:48&nbsp;来自三星GALAXY A',
 'commentNumber': '赞[2]',
 'content': '服了[赞]',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/005QLEH6ly1fkcyvixwedj30k00m6gnq.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:00:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5360391480/profile?filter=1&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 132, in parseWeiBo
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:01:02 [scrapy.extensions.logstats] INFO: Crawled 111 pages (at 23 pages/min), scraped 798 items (at 178 items/min)
2018-07-24 17:01:11 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝95人',
 'headshot': 'http://tva3.sinaimg.cn/crop.0.0.200.200.50/005GCWaMjw1ezgbmcvjv5j305k05kaa6.jpg',
 'name': 'Sophia汤先來林</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝730人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5210550356&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/hboproducts"><img '
         'src="http://tva3.sinaimg.cn/crop.0.0.180.180.50/61e6bc98jw1e8qgp5bmzyj2050050aa8.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/hboproducts">Delicate黄</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝31889人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1642511512&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/2072768374"><img '
         'src="http://tva3.sinaimg.cn/crop.0.17.640.640.50/7b8bef76jw8e7l0vjlzcfj20hs0iq3zq.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/2072768374">O倔V强O'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:01:11 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝1人',
 'headshot': 'http://tva2.sinaimg.cn/crop.0.0.1080.1080.50/4d8273bcjw8eos167u4hwj20u00u00tz.jpg',
 'name': '尤_勇</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝473人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1300394940&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6572212100"><img '
         'src="http://tvax4.sinaimg.cn/crop.0.0.40.40.50/007aMkAYly8fs6verdho8j3014014741.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6572212100">用户6572212100'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:01:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5871897095/follow?page=8> (referer: https://weibo.cn/5871897095/follow?page=7)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:01:53 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝26人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.4.1242.1242.50/60e749d6ly8fdzxw0ychlj20yi0yq0wy.jpg',
 'name': '波比童鞋是吃货</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝500人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1625770454&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6441763855"><img '
         'src="http://tvax2.sinaimg.cn/crop.0.0.512.512.50/0071WZ31ly8fq6587o1fgj30e80e8mxh.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6441763855">艳若桃李完美无暇'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:02:02 [scrapy.extensions.logstats] INFO: Crawled 136 pages (at 25 pages/min), scraped 968 items (at 170 items/min)
2018-07-24 17:02:03 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5360391480',
 'fansTotal': '粉丝214人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.600.600.50/9c92bfc0jw8ez1ngzfn7jj20go0got9r.jpg',
 'name': '重庆搜号网</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5337.gif" '
         'alt="V"/><br/>粉丝15810人<br/><a '
         'href="https://weibo.cn/attention/add?uid=2626863040&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/2019266742"><img '
         'src="http://tva4.sinaimg.cn/crop.0.0.180.180.50/785b90b6jw1e8qgp5bmzyj2050050aa8.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/2019266742">DODO小倩'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:02:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5360391480/fans?page=3> (referer: https://weibo.cn/5360391480/fans?page=2)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:02:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5360391480/follow?page=4> (referer: https://weibo.cn/5360391480/follow?page=3)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:02:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5781188745/fans?page=2> (referer: https://weibo.cn/5781188745/fans)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:02:37 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝16人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.512.512.50/0078tDW9ly8fsr2n52d4wj30e80e8dgk.jpg',
 'name': '特里罗齐尔篮球资讯</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝2663人<br/><a '
         'href="https://weibo.cn/attention/add?uid=6538205545&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5911630934"><img '
         'src="http://tvax1.sinaimg.cn/crop.0.0.1242.1242.50/006s4Bg2ly8fs6j37vt6xj30yi0yigog.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5911630934">你是扑面而来的善意'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:02:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5781188745',
 'comeFrom': '04月11日 09:09&nbsp;来自趣测君',
 'commentNumber': '赞[0]',
 'content': '我的强迫症指数是28',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/006jfhhLly1fq8g2933ohj30ku0c8tjo.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:02:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5781188745',
 'comeFrom': '01月22日 09:02&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '原图',
 'content': '这个人，不论是候车还是运行时间，全程都在录唱？！关键是还很不好听啊！乘务员不能管管吗？好想按键叫人啊，结果发现高铁没有按键啊[怒][怒] ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://wx4.sinaimg.cn/wap180/006jfhhLgy1fnp3u6bpuxj30qo0zkdnk.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:02:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5781188745',
 'comeFrom': '01月06日 15:00&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '赞[0]',
 'content': '老公在玩三国英雄传',
 'goodNumber': '上海·御上海',
 'transmitNumber': '显示地图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:02:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5781188745',
 'comeFrom': '2017-12-08 23:00:15&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '组图共3张',
 'content': '玲珑骰子安红豆[鼓掌]这是某人的生日礼物',
 'goodNumber': '上海·御上海',
 'transmitNumber': '显示地图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:02:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5781188745',
 'comeFrom': '2017-11-09 09:10:38&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '<img '
                  'src="http://wx4.sinaimg.cn/wap180/006jfhhLgy1flbk9ryjiuj30qo1bfn4f.jpg" '
                  'alt="图片" class="ib" />',
 'content': '',
 'goodNumber': '厦门·莲前街区',
 'transmitNumber': '显示地图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:02:46 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5781188745',
 'comeFrom': '2017-11-04 16:44:15&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '<img '
                  'src="http://wx2.sinaimg.cn/wap180/006jfhhLgy1fl659exos4j30qo1bf452.jpg" '
                  'alt="图片" class="ib" />',
 'content': '对不起…花…大概你活不过明天[允悲][允悲] ',
 'goodNumber': '显示地图',
 'transmitNumber': '组图共4张'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:02:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5781188745/profile?filter=1&page=1> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 132, in parseWeiBo
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:03:02 [scrapy.extensions.logstats] INFO: Crawled 157 pages (at 21 pages/min), scraped 1132 items (at 164 items/min)
2018-07-24 17:03:04 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'fansTotal': '粉丝27人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.0.512.512.50/7046a72ely8ftckfwmozyj20e80e83za.jpg',
 'name': 'CHEN__XIAOYI</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝231人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1883678510&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5410661143"><img '
         'src="http://tvax4.sinaimg.cn/crop.0.0.1242.1242.50/005UaA87ly8fss662uk3nj30yi0yidhr.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5410661143">是什么晗-'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:03:19 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5676304901/follow?page=11> (referer: https://weibo.cn/5676304901/follow?page=10)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:03:21 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝1人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.925.925.50/8e0687ebly8fjmg73j98gj20pp0ppgo2.jpg',
 'name': '淡漠丨灬浮华</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝69人<br/><a '
         'href="https://weibo.cn/attention/add?uid=2382792683&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6468358557"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.0.996.996.50/0073KzxPly8fnpijpi3jfj30ro0rogo3.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6468358557">傻库2'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:03:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/3958189286/follow> (referer: None)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:03:47 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'fansTotal': '粉丝86人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.179.1080.1080.50/006qQeSNly1frmkc53te1j30u013yacu.jpg',
 'name': '_Shift_Delete启宗基</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝1542人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5893431997&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/3202111320"><img '
         'src="http://tvax1.sinaimg.cn/default/images/default_avatar_male_50.gif" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/3202111320">永不湮灭22'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:03:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'comeFrom': '07月21日 23:13&nbsp;来自柔光自拍vivo X7Plus',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': '#镇魂#',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/ebed2ce6gy1fthvx728kwj21hc0u0qjd.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:03:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'comeFrom': '07月20日 09:33&nbsp;来自柔光自拍vivo X7Plus',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': '组图共7张',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/ebed2ce6gy1ftg2phks58j20j60j8t9s.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:03:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'comeFrom': '07月19日 22:48&nbsp;来自柔光自拍vivo X7Plus',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': '组图共9张',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/ebed2ce6gy1ftfjzkuvp6j20c80got99.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:03:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'comeFrom': '07月19日 19:07&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[0]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/ebed2ce6gy1ftfdo7lj2qj20rc0i6jue.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:03:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'comeFrom': '07月19日 10:32&nbsp;来自柔光自拍vivo X7Plus',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': '组图共9张',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/ebed2ce6gy1fteysj3mr2j20cv05tq3e.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:03:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'comeFrom': '07月19日 10:20&nbsp;来自柔光自拍vivo X7Plus',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': '组图共8张',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/ebed2ce6gy1fteydjyvlrj20t409wgu1.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:03:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'comeFrom': '07月19日 10:08&nbsp;来自微博 weibo.com',
 'commentNumber': '赞[0]',
 'content': '【14.9】滋源 生姜无硅油洗护旅行装235+120ml \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx4.sinaimg.cn/wap180/ebed2ce6ly1ftey3jz2p0j20m80m8ad7.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:03:57 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'comeFrom': '07月19日 09:55&nbsp;来自微博 weibo.com',
 'commentNumber': '原图',
 'content': '【18.9】回力 情侣凉拖 \u200b\u200b\u200b',
 'goodNumber': '组图共3张',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/ebed2ce6ly1ftewowlhnpj20m80m8qbk.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:04:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝262人',
 'headshot': 'http://tva4.sinaimg.cn/crop.39.6.291.291.50/675dc841jw1edpsyy1sdcj20c808yaav.jpg',
 'name': '庞祯敬</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝7095人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1734199361&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/407920234"><img '
         'src="http://tva2.sinaimg.cn/crop.0.0.1242.1242.50/68bafd19jw8f53bbya5oij20yi0yiacp.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/407920234">吴蘑蘑是也</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝877人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1757084953&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5704402623"><img '
         'src="http://tvax2.sinaimg.cn/crop.0.0.1342.1342.50/006e35HVly8fn853j1ciej311a11bjwr.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5704402623">不能再喝了先生'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:04:02 [scrapy.extensions.logstats] INFO: Crawled 181 pages (at 24 pages/min), scraped 1306 items (at 174 items/min)
2018-07-24 17:04:25 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'fansTotal': '粉丝122人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.888.888.50/7f3ebef9ly8fs1x767ktnj20oo0oogne.jpg',
 'name': '_Anser丶</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝530人<br/><a '
         'href="https://weibo.cn/attention/add?uid=2134818553&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5648851190"><img '
         'src="http://tva2.sinaimg.cn/crop.0.0.1002.1002.50/006ai0f4jw8fb8yvevx7kj30ru0rutcy.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5648851190">POPPY0n'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:05:02 [scrapy.extensions.logstats] INFO: Crawled 200 pages (at 19 pages/min), scraped 1460 items (at 154 items/min)
2018-07-24 17:05:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/2517436943/follow?page=12> (referer: https://weibo.cn/2517436943/follow?page=11)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:05:52 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'fansTotal': '粉丝27人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.0.200.200.50/005HBpRIly1fpj48ge0p2j305k05kwev.jpg',
 'name': 'try0003愈槐愈</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝973人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5224964174&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6301477026"><img '
         'src="http://tvax4.sinaimg.cn/crop.0.0.996.996.50/006Ssm2ely8fha4kcx3hnj30ro0rogm2.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6301477026">学霸昨日重现1997'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:05:59 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5369689800',
 'comeFrom': '07月23日 13:05&nbsp;来自iPhone 6s',
 'commentNumber': '原图',
 'content': '福利走一波！不举报我我们还是好朋友[污] \u200b\u200b\u200b',
 'goodNumber': '组图共9张',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/005RoFC0ly1ftjpn3eg2xj30ku0mngo5.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:05:59 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5369689800',
 'comeFrom': '07月23日 12:11&nbsp;来自iPhone 6s',
 'commentNumber': '赞[439]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/005RoFC0ly1ftjo1rt73aj30iy0iy40i.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:05:59 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5369689800',
 'comeFrom': '07月22日 23:13&nbsp;来自iPhone 6s',
 'commentNumber': '原图',
 'content': '无意中翻到了～从2013年中国赛零星几个球迷组成的看球团体，到如今仅一个地区看球团体就有如此多的球迷，不得不感叹勇士是有多么的成功啊！ '
            '\u200b\u200b\u200b',
 'goodNumber': '组图共2张',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/005RoFC0ly1ftj1o0xpqnj30j60ed430.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:05:59 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5369689800',
 'comeFrom': '07月19日 23:07&nbsp;来自iPhone 6s',
 'commentNumber': '<img '
                  'src="http://wx3.sinaimg.cn/wap180/005RoFC0ly1ftfk4b9o7hg307b073e83.gif" '
                  'alt="图片" class="ib" />',
 'content': '一晃眼6岁啦！一起来祝我们的小女神Riley生日快乐！[蛋糕][蛋糕][蛋糕]',
 'goodNumber': '全文',
 'transmitNumber': '组图共9张'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'commentNumber' at row 1")
2018-07-24 17:05:59 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5369689800',
 'comeFrom': '07月19日 12:32&nbsp;来自iPhone 6s',
 'commentNumber': '<img '
                  'src="http://wx1.sinaimg.cn/wap180/005RoFC0ly1ftf22gc13nj30rs0zxqpf.jpg" '
                  'alt="图片" class="ib" />',
 'content': "库里登上《variety》杂志封面，为其拍摄写真。小学生曾在西决上爆粗口''This is my fuxxing "
            "house''，赛后被妈妈教训说要用肥皂好好洗嘴巴[笑cry]确认过牙缝，我遇上对的人[允悲]",
 'goodNumber': '全文',
 'transmitNumber': '组图共5张'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'commentNumber' at row 1")
2018-07-24 17:05:59 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5369689800',
 'comeFrom': '07月18日 23:22&nbsp;来自iPhone 6s',
 'commentNumber': '赞[474]',
 'content': '简而言之，库里是国民老公，无数女孩都想嫁的那种[米奇比心][米奇比心][米奇比心] \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/005RoFC0ly1ftefcpezeij30qo0x3dsg.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:06:02 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝1060人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.277.631.631.50/6e275cd7jw8f3pk9j8an4j20hs0vkju9.jpg',
 'name': 'kitchen_and_love</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝565人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1848073431&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5836032738"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.0.996.996.50/006mXoIily8fqaeg9pju0j30ro0ro417.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5836032738">LJSunShinePlus'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:06:02 [scrapy.extensions.logstats] INFO: Crawled 224 pages (at 24 pages/min), scraped 1633 items (at 173 items/min)
2018-07-24 17:06:31 [scrapy.core.scraper] ERROR: Error processing {'blogger': '2139359753',
 'fansTotal': '粉丝87人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.180.180.50/654deb77jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '戴红帽子的鱼</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝382人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1699605367&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/3674015967"><img '
         'src="http://tvax1.sinaimg.cn/crop.0.0.996.996.50/dafd08dfly8fthsflmvrzj20ro0ro74j.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/3674015967">小奶橘_'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:06:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'fansTotal': '粉丝120人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.996.996.50/beebba41ly8fs7oxjpb9sj20ro0roacw.jpg',
 'name': '六六六六六六金ye</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝605人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3203119681&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/3185037720"><img '
         'src="http://tvax1.sinaimg.cn/crop.0.0.751.751.50/bdd7d198ly8ftfkpfao19j20kv0kvq3m.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/3185037720">凯西国际小站'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:06:44 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝316人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.1200.1200.50/6736e788jw8ecasy06kuzj20xc0xcq5b.jpg',
 'name': 'Sher-LOCKer</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝447人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1731651464&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/1864560643"><img '
         'src="http://tvax2.sinaimg.cn/crop.0.0.812.812.50/6f22f003ly8foxsookyipj20mk0mkwft.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/1864560643">爱尔兰吃麻兽'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:07:02 [scrapy.extensions.logstats] INFO: Crawled 248 pages (at 24 pages/min), scraped 1827 items (at 194 items/min)
2018-07-24 17:07:16 [scrapy.core.scraper] ERROR: Error processing {'blogger': '3958189286',
 'fansTotal': '粉丝48人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.0.0.1080.1080.50/005NKi0Kly1fo0xuiazekj30u00u00tx.jpg',
 'name': '阿K__军灵</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝1046人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5315736950&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5242718214"><img '
         'src="http://tvax1.sinaimg.cn/crop.0.0.996.996.50/005INUvcly8ftfke1hgp1j30ro0romyl.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5242718214">上哈佛幼儿园的三岁盆友'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:07:24 [scrapy.core.scraper] ERROR: Error processing {'blogger': '1922233745',
 'comeFrom': '07月20日 22:23&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '<img '
                  'src="http://wx4.sinaimg.cn/wap180/7292f591gy1ftgox5fz9bj20v81awu0x.jpg" '
                  'alt="图片" class="ib" />',
 'content': '罚篮黑洞喽[泪]哎没别的办法，苦练吧少年[拳头]',
 'goodNumber': '连云港·新浦区',
 'transmitNumber': '显示地图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:07:24 [scrapy.core.scraper] ERROR: Error processing {'blogger': '1922233745',
 'comeFrom': '07月18日 22:31&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '<img '
                  'src="http://wx1.sinaimg.cn/wap180/7292f591ly1ftedwv71nlj2334229x6q.jpg" '
                  'alt="图片" class="ib" />',
 'content': '夏天第一场比赛，就是国家队比赛。好久没有正式比赛了还真有些不适应，总算打的还算对得起观众[互粉] ',
 'goodNumber': '显示地图',
 'transmitNumber': '组图共2张'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:07:24 [scrapy.core.scraper] ERROR: Error processing {'blogger': '1922233745',
 'comeFrom': '07月16日 13:16&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '原图',
 'content': '今天北京天气不好，这出去比赛也是够折腾的了。[轻轨]北京—山东—江苏（徐州市）[巴士]河南（永城市）一折腾又是一天。早上七点小伙伴一起出发的，看看几点可以到[我想静静]',
 'goodNumber': '#盛夏光影#',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/7292f591ly1ftbmon5299j20v815ke81.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:07:24 [scrapy.core.scraper] ERROR: Error processing {'blogger': '1922233745',
 'comeFrom': '07月15日 21:39&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '原图',
 'content': '法国小胜，今天算毒奶嘛[污] \u200b\u200b\u200b',
 'goodNumber': '组图共2张',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/7292f591ly1ftavlp1gvyj20k00ahwez.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:07:24 [scrapy.core.scraper] ERROR: Error processing {'blogger': '1922233745',
 'comeFrom': '07月10日 08:16&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '组图共2张',
 'content': '今天站边比利时，稳稳的。',
 'goodNumber': '北京·国家体育总局田径场',
 'transmitNumber': '显示地图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:07:24 [scrapy.core.scraper] ERROR: Error processing {'blogger': '1922233745',
 'comeFrom': '07月08日 20:43&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '原图',
 'content': '要很长一段时间见不到家人了，做了一顿大餐给他们吃，还给他们包了够两个月吃的饺子\U0001f95f。实际效果很好的，色香味俱全！照片只能怪摄像师水平太差',
 'goodNumber': '组图共6张',
 'transmitNumber': '<img '
                   'src="http://wx4.sinaimg.cn/wap180/7292f591ly1ft2dym594hj21w02io1l4.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect string value: '\\xF0\\x9F\\xA5\\x9F\\xE3\\x80...' for column 'content' at row 1")
2018-07-24 17:07:24 [scrapy.core.scraper] ERROR: Error processing {'blogger': '1922233745',
 'comeFrom': '06月29日 09:13&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '赞[495]',
 'content': '祈福[可怜][可怜][可怜] \u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx1.sinaimg.cn/wap180/7292f591gy1fsrs4m2yrtj20ty1hcgok.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:07:24 [scrapy.core.scraper] ERROR: Error processing {'blogger': '1922233745',
 'comeFrom': '06月27日 23:43&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '原图',
 'content': '有多少人在为德国战车，紧张！加油呢！阿根廷踩着黄线进入复赛！德国呢[污] ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/7292f591gy1fsq60fodzaj23402c0npd.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'comeFrom' at row 1")
2018-07-24 17:07:24 [scrapy.core.scraper] ERROR: Error processing {'blogger': '1922233745',
 'comeFrom': '06月11日 17:23&nbsp;来自<a '
             'href="https://weibo.cn/sinaurl?f=w&amp;u=http%3A%2F%2Fdown.sina.cn%2Fsinaclient%2Fweibo%2Findex%2Fgsid%2F0%2Fmid%2F0">iPhone客户端</a>',
 'commentNumber': '<img '
                  'src="http://wx4.sinaimg.cn/wap180/7292f591gy1fs7d4uipyyj22c0340b29.jpg" '
                  'alt="图片" class="ib" />',
 'content': '这一天，现在算是结束了🔚！明天继续 ',
 'goodNumber': '显示地图',
 'transmitNumber': '组图共2张'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect string value: '\\xF0\\x9F\\x94\\x9A\\xEF\\xBC...' for column 'content' at row 1")
2018-07-24 17:07:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5781188745/follow?page=10> (referer: https://weibo.cn/5781188745/follow?page=9)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:08:02 [scrapy.extensions.logstats] INFO: Crawled 273 pages (at 25 pages/min), scraped 2020 items (at 193 items/min)
2018-07-24 17:08:07 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝66人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.720.720.50/46a34909jw8eraroa935qj20k00k00tv.jpg',
 'name': '平金一生</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝1046人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1185106185&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5647582362"><img '
         'src="http://tvax4.sinaimg.cn/crop.15.0.1212.1212.50/006acGa6ly8frtrqrjm2aj30yi0xoac8.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5647582362">飛曼-FlyShow'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:08:28 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'fansTotal': '粉丝134人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.750.750.50/795386a9jw8eypiyzib4pj20ku0kvtal.jpg',
 'name': 'Aa-may-</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝264人<br/><a '
         'href="https://weibo.cn/attention/add?uid=2035517097&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5869449754"><img '
         'src="http://tvax3.sinaimg.cn/crop.21.0.1083.1083.50/006pdC0qly8fr4k605v07j30v90u3776.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5869449754">久本发型_a迪'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:08:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'fansTotal': '粉丝44人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.0.751.751.50/005G8Tzply8fqw9kqscpkj30kv0kv75j.jpg',
 'name': '转手残木油壁界诗</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝1518人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5203390511&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6576066604"><img '
         'src="http://tvax2.sinaimg.cn/crop.27.17.68.68.50/007b2vkoly8fsd0daz08mj3030030dft.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6576066604">子化己是去阿都不carry'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:08:33 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'fansTotal': '粉丝71人',
 'headshot': 'http://tvax2.sinaimg.cn/crop.14.0.722.722.50/006Mm0SYly8fmtxvcrdyvj30ku0k275u.jpg',
 'name': '赴韩整容翻译小于同学</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝10968人<br/><a '
         'href="https://weibo.cn/attention/add?uid=6211307744&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5224301191"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.0.200.200.50/005HyDorly1fpj46urt64j305k05kt8t.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5224301191">Piscees希</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝795人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5224301191&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6577141897"><img '
         'src="http://tvax2.sinaimg.cn/crop.0.0.1242.1242.50/007b713Ply8fsf78r58u3j30yi0yidie.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6577141897">Grace姥姥2018'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:09:02 [scrapy.extensions.logstats] INFO: Crawled 296 pages (at 23 pages/min), scraped 2194 items (at 174 items/min)
2018-07-24 17:09:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'fansTotal': '粉丝116人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.180.180.50/6aac47c7jw1f4eoekk09tj205005074m.jpg',
 'name': '小Yink</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝1929人<br/><a '
         'href="https://weibo.cn/attention/add?uid=1789675463&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5851924914"><img '
         'src="http://tvax4.sinaimg.cn/crop.0.0.996.996.50/006o24ZIly8fqzu6csrclj30ro0ro0t2.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5851924914">Eye丶Slugger'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:09:12 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6397910297',
 'fansTotal': '粉丝2人',
 'headshot': 'http://tvax4.sinaimg.cn/crop.0.0.996.996.50/9f394d0dly8fr3x45txqqj20ro0roac1.jpg',
 'name': '阿佳是小仙女啊</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝112人<br/><a '
         'href="https://weibo.cn/attention/add?uid=2671332621&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5642079423"><img '
         'src="http://tvax2.sinaimg.cn/crop.0.11.1242.1242.50/0069PAB1ly8fkam4yll15j30yi0z4418.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5642079423">美食铺93158'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:09:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'fansTotal': '粉丝948人',
 'headshot': 'http://tva1.sinaimg.cn/crop.0.0.180.180.50/805fe0e8jw1e8qgp5bmzyj2050050aa8.jpg',
 'name': '金屋藏枚傻瓜妞儿_159</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝369人<br/><a '
         'href="https://weibo.cn/attention/add?uid=2153767144&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5205419258"><img '
         'src="http://tva1.sinaimg.cn/crop.0.0.200.200.50/005Ghpl8jw1ezrzgy3cfrj305k05kjrk.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5205419258">陈莉01瑰</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝317人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5205419258&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6234655371"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.0.512.512.50/006NVYFBly8fpa27nnd0sj30e80e8mxd.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6234655371">落白菜</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝1386人<br/><a '
         'href="https://weibo.cn/attention/add?uid=6234655371&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/1784047625"><img '
         'src="http://tva1.sinaimg.cn/crop.0.0.720.720.50/6a566809jw8ek5mxiw1l6j20k00k0q4a.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/1784047625">大胆逆臣'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:09:18 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'fansTotal': '粉丝68人',
 'headshot': 'http://tva4.sinaimg.cn/crop.0.0.200.200.50/005Hv2eKjw1ezxvy0dqpsj305k05kt8w.jpg',
 'name': '彦焕明舒</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝240人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5223443378&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6557058379"><img '
         'src="http://tvax4.sinaimg.cn/crop.27.17.68.68.50/0079KKq7ly8frk9hdv0lgj3030030jrl.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6557058379">登峰造极oaq'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:09:36 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5676304901',
 'fansTotal': '粉丝85人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.0.996.996.50/93993107ly8frbtl9muyjj20ro0rodik.jpg',
 'name': 'DaddyRachel</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5547.gif" '
         'alt="达人"/><br/>粉丝379人<br/><a '
         'href="https://weibo.cn/attention/add?uid=2476290311&amp;rl=1&amp;st=94e1b8">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/3637978310"><img '
         'src="http://tvax1.sinaimg.cn/crop.0.0.996.996.50/d8d724c6ly8fip4id2j70j20ro0rotao.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/3637978310">张鼠妇'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:09:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5676304901/fans?page=20> (referer: https://weibo.cn/5676304901/fans?page=19)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:09:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/2517436943/fans?page=18> (referer: https://weibo.cn/2517436943/fans?page=17)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:09:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5871897095/fans?page=20> (referer: https://weibo.cn/5871897095/fans?page=19)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:10:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'fansTotal': '粉丝40人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.149.149.50/7f5c795bgy1fe5ush1pz0j2046046t92.jpg',
 'name': '小年Ann</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝384人<br/><a '
         'href="https://weibo.cn/attention/add?uid=2136766811&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5210810926"><img '
         'src="http://tvax3.sinaimg.cn/crop.324.0.1080.1080.50/005GE1Xwly1fppwxmia95j31c00u0jtd.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5210810926">wg204wg懂</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝883人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5210810926&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5233749672"><img '
         'src="http://tva3.sinaimg.cn/crop.0.0.200.200.50/005Ichnijw1eqln3uukn2j305k05kdfy.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5233749672">幸福柳真花园建</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝263人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5233749672&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6442992837"><img '
         'src="http://tvax4.sinaimg.cn/crop.43.0.153.153.50/007228Ljly1fms4tdvka4j306o049wf0.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6442992837">犯愁寒冷孤单落</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝125人<br/><a '
         'href="https://weibo.cn/attention/add?uid=6442992837&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5221825762"><img '
         'src="http://tva2.sinaimg.cn/crop.0.0.200.200.50/005Hofqajw1eyrtauwf3uj305k05kq3b.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5221825762">若冶秀益</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝222人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5221825762&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/3223184142"><img '
         'src="http://tva1.sinaimg.cn/crop.0.0.200.200.50/c01de30ejw1fbwjoio5ggj205k05kmwz.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/3223184142">银河卡柏_Bili</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝597人<br/><a '
         'href="https://weibo.cn/attention/add?uid=3223184142&amp;rl=1&amp;st=ef4a23">关注他</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6093637147"><img '
         'src="http://tvax1.sinaimg.cn/crop.0.0.1006.1006.50/006Eoho7ly8ftcqizgqs0j30ry0ryju0.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6093637147">蓝二么'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:10:00 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'fansTotal': '粉丝10人',
 'headshot': 'http://tvax3.sinaimg.cn/crop.0.201.664.664.50/006BzXsjly8fk7dbuo2l8j30ig0o2zup.jpg',
 'name': '熙瑶女</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝807人<br/><a '
         'href="https://weibo.cn/attention/add?uid=6052091455&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/5923878113"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.18.925.925.50/006sTZjbly8fjxxemi4tcj30pp0qpjte.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/5923878113">继红_才呀</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝14067人<br/><a '
         'href="https://weibo.cn/attention/add?uid=5923878113&amp;rl=1&amp;st=ef4a23">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6581924416"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.0.100.100.50/007br5dely8fsld0vu5hhj302s02sweb.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6581924416">敲汗凭桥锌灬'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:10:02 [scrapy.extensions.logstats] INFO: Crawled 319 pages (at 23 pages/min), scraped 2374 items (at 180 items/min)
2018-07-24 17:10:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/2139359753/follow?page=20> (referer: https://weibo.cn/2139359753/follow?page=19)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:10:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/2139359753/fans?page=20> (referer: https://weibo.cn/2139359753/fans?page=19)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:10:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5579672076/fans?page=20> (referer: https://weibo.cn/5579672076/fans?page=19)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 89, in parseFans
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-24 17:10:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-11-22 16:21:06&nbsp;来自陌陌',
 'commentNumber': '原图',
 'content': '',
 'goodNumber': 'http://t.cn/R7EiPUE',
 'transmitNumber': '<img '
                   'src="http://ww3.sinaimg.cn/wap180/005IkdlWjw1emjumeh50oj30e70gv78l.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:10:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-11-13 09:15:55&nbsp;来自陌陌',
 'commentNumber': '原图',
 'content': '我在陌陌，陌陌号：89240017，愿得一人心，白首不相离。。',
 'goodNumber': 'http://t.cn/R7eOeqQ',
 'transmitNumber': '<img '
                   'src="http://ww2.sinaimg.cn/wap180/005IkdlWjw1em93r88n42j30go0miq4q.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:10:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-09-05 11:50:50&nbsp;来自新浪微博4G版',
 'commentNumber': '原图',
 'content': '这狗狗乖不 ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://ww1.sinaimg.cn/wap180/005IkdlWjw1ek1gbda3edj30xc18g448.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:10:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-08-28 17:30:02&nbsp;来自新浪微博4G版',
 'commentNumber': '原图',
 'content': '分享图片 ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://ww4.sinaimg.cn/wap180/005IkdlWjw1ejshbleyj1j30hs0dcdgu.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:10:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-08-15 15:47:09&nbsp;来自新浪微博4G版',
 'commentNumber': '原图',
 'content': '分享图片 ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://ww1.sinaimg.cn/wap180/005IkdlWjw1ejddahv3nsj30hs0npq46.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:10:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-08-14 08:42:00&nbsp;来自新浪微博4G版',
 'commentNumber': '原图',
 'content': '这样的基友就该拖出去宰了 ',
 'goodNumber': '显示地图',
 'transmitNumber': '<img '
                   'src="http://ww1.sinaimg.cn/wap180/005IkdlWjw1ejbvdjekdqj318g0xcn2c.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:10:13 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5235640836',
 'comeFrom': '2014-08-13 15:16:40&nbsp;来自分享按钮',
 'commentNumber': '<img '
                  'src="http://ww4.sinaimg.cn/wap180/005IkdlWjw1ejb16841avj30f50bdq6x.jpg" '
                  'alt="图片" class="ib" />',
 'content': '【女子公园放生毒蛇引争议 网友斥其“放生无下限”】下载查看：',
 'goodNumber': '@百度新闻',
 'transmitNumber': '女子公园放生毒蛇引争议 网友斥其“放生无下限”'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:10:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'comeFrom': '今天 10:18&nbsp;来自HUAWEI nova 2s',
 'commentNumber': '原图',
 'content': '祛除妊娠斑可以通过食疗、美容、自作面膜等方法，但是最重要的还是使用正规医院研发的祛斑产品，不要擅自使用没有相关资质的祛斑产品。使用北京301研发的“老三样”后，妊娠斑将会被成功祛除，这样你又可以拥有白皙稚嫩的肌肤了。当你祛斑成功后，收获的不仅仅是做妈妈的乐趣，更能收到别人羡慕的目光 '
            '\u200b\u200b\u200b&nbsp;',
 'goodNumber': '组图共5张',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/0078cv5dly1ftkqhlgj8ej30qo19rdjo.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:10:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'comeFrom': '07月23日 11:27&nbsp;来自HUAWEI nova 2s',
 'commentNumber': '原图',
 'content': '🔻优斐斯传明酸作用多多[强] [强] '
            '，它不仅可以淡化黑色素，可以告别黄脸婆，调理肤色不均，暗沉枯黄，还可以用来当做眼部精华，淡化黑眼圈，修复痘印和斑点等。[emoji] '
            '[emoji] '
            '激光术后，可以有效防止反黑，还具有去除面部淤青淤红的作用。很多朋友做了激光后会再次色素沉淀，用这款传明酸是最佳的选择。 '
            '\u200b\u200b\u200b&nbsp;',
 'goodNumber': '组图共3张',
 'transmitNumber': '<img '
                   'src="http://wx1.sinaimg.cn/wap180/0078cv5dly1ftjmvc6e4ij30u00u04b1.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.InternalError: (1366, "Incorrect string value: '\\xF0\\x9F\\x94\\xBB\\xE4\\xBC...' for column 'content' at row 1")
2018-07-24 17:10:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'comeFrom': '07月23日 09:07&nbsp;来自HUAWEI nova 2s',
 'commentNumber': '赞[0]',
 'content': '中医院润肤丸，北京中医医院皮肤科创始人、中医皮外科界的泰斗赵炳南老先生研制，清热养阴，活血润肤，祛风止痒。用于神经性皮炎，湿疹（鹅掌风），皮肤皲裂。 '
            '\u200b\u200b\u200b',
 'goodNumber': '<img '
               'src="http://wx3.sinaimg.cn/wap180/0078cv5dly1ftjitn479xj30u0142h0v.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:10:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'comeFrom': '07月23日 08:57&nbsp;来自HUAWEI nova 2s',
 'commentNumber': '原图',
 'content': '空军总医院防晒霜',
 'goodNumber': '组图共3张',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/0078cv5dly1ftjijagjdlj30cs0m80wy.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:10:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'comeFrom': '07月23日 07:25&nbsp;来自HUAWEI nova 2s',
 'commentNumber': '原图',
 'content': '药妆  ',
 'goodNumber': '组图共9张',
 'transmitNumber': '<img '
                   'src="http://wx2.sinaimg.cn/wap180/0078cv5dly1ftjfuahqfaj30ku0bon0l.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:10:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'comeFrom': '07月22日 19:44&nbsp;来自HUAWEI nova 2s',
 'commentNumber': '赞[0]',
 'content': '',
 'goodNumber': '<img '
               'src="http://wx2.sinaimg.cn/wap180/0078cv5dly1ftivmjnfu8j30ty1k816k.jpg" '
               'alt="图片" class="ib" />',
 'transmitNumber': '原图'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:10:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'comeFrom': '07月22日 12:30&nbsp;来自HUAWEI nova 2s',
 'commentNumber': '转发[0]',
 'content': '我发表了头条文章:《医美面膜针对',
 'goodNumber': '医美面膜针对 问题肌肤的总结',
 'transmitNumber': '赞[0]'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'goodNumber' at row 1")
2018-07-24 17:10:22 [scrapy.core.scraper] ERROR: Error processing {'blogger': '6534119935',
 'comeFrom': '07月22日 10:15&nbsp;来自HUAWEI nova 2s',
 'commentNumber': '原图',
 'content': '【[四叶草]北京301医院[喇叭]舒缓膏[四叶草]】',
 'goodNumber': '全文',
 'transmitNumber': '<img '
                   'src="http://wx3.sinaimg.cn/wap180/0078cv5dly1ftif66986vj30ia0podpi.jpg" '
                   'alt="图片" class="ib" />'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 33, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'transmitNumber' at row 1")
2018-07-24 17:10:30 [scrapy.core.scraper] ERROR: Error processing {'blogger': '5369689800',
 'fansTotal': '粉丝66人',
 'headshot': 'http://tvax1.sinaimg.cn/crop.0.0.365.365.50/006XdAjSgy1ft85rx0chyj30a60a6jrq.jpg',
 'name': 'Trend席紫易</a><img '
         'src="https://h5.sinaimg.cn/upload/2016/05/26/319/5338.gif" '
         'alt="V"/><br/>粉丝79人<br/><a '
         'href="https://weibo.cn/attention/add?uid=6371838696&amp;rl=1&amp;st=94e1b8">关注她</a></td></tr></table> '
         '<div class="s"></div><table><tr><td valign="top" style="width: '
         '52px"><a href="https://weibo.cn/u/6213489960"><img '
         'src="http://tvax3.sinaimg.cn/crop.0.0.498.498.50/006MvaA0ly8fpbyor3oqsj30du0du751.jpg" '
         'alt="pic" /></a></td><td valign="top"><a '
         'href="https://weibo.cn/u/6213489960">扣篮逆天'}
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\pipelines.py", line 19, in process_item
    db.otherOprate(sql, params=params)
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\util\sqlUtil.py", line 51, in otherOprate
    self.cursor.execute(sql, params)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 165, in execute
    result = self._query(query)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\cursors.py", line 321, in _query
    conn.query(q)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 860, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1061, in _read_query_result
    result.read()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1349, in read
    first_packet = self.connection._read_packet()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 1018, in _read_packet
    packet.check_error()
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\connections.py", line 384, in check_error
    err.raise_mysql_exception(self._data)
  File "C:\Users\Administrator\AppData\Roaming\Python\Python36\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.DataError: (1406, "Data too long for column 'name' at row 1")
2018-07-24 17:10:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://weibo.cn/5235640836/follow?page=20> (referer: https://weibo.cn/5235640836/follow?page=19)
Traceback (most recent call last):
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\middlewares.py", line 34, in process_spider_output
    for i in result:
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "C:\Users\Administrator\AppData\Local\Programs\Python\Python36-32\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\pyfile\爬虫\使用scrapy\sina\sina\spiders\sina_spider.py", line 65, in parseAttention
    nextpage = r'https://weibo.cn' + nextpage[0]
IndexError: list index out of range
2018-07-25 21:26:51 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-25 21:26:51 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-25 21:26:51 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-25 21:26:51 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-07-30 10:50:03 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: sina)
2018-07-30 10:50:03 [scrapy.utils.log] INFO: Versions: lxml 4.2.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.4.0, w3lib 1.19.0, Twisted 17.9.0, Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)], pyOpenSSL 17.5.0 (OpenSSL 1.1.0h  27 Mar 2018), cryptography 2.2.2, Platform Windows-7-6.1.7601-SP1
2018-07-30 10:50:03 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'sina', 'CONCURRENT_REQUESTS': 32, 'DOWNLOAD_DELAY': 2, 'LOG_FILE': 'SinaSpider.log', 'LOG_LEVEL': 'INFO', 'NEWSPIDER_MODULE': 'sina.spiders', 'SPIDER_MODULES': ['sina.spiders']}
2018-07-30 10:50:03 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
